[{"categories":null,"content":"debuginn's friends","date":"2023-02-25","objectID":"/friends/","tags":null,"title":"友情链接","uri":"/friends/"},{"categories":null,"content":"申请友联 申请友情链接的话请提交 issue 来申请。 - nickname: Debug客栈 avatar: https://image.debuginn.cn/202302182238057.JPG url: https://debuginn.cn description: 做一个爱分享的程序猿 ","date":"2023-02-25","objectID":"/friends/:1:0","tags":null,"title":"友情链接","uri":"/friends/"},{"categories":null,"content":"友情提示 Notice 如果您想交换链接，请按上述格式留言。(仅限个人非商业性博客网站)；  网站出现故障、停止维护和不当内容可能会被取消链接！ 那些不尊重他人劳动成果、无源转载、恶意行为的网站，请不要前来交流。 ","date":"2023-02-25","objectID":"/friends/:2:0","tags":null,"title":"友情链接","uri":"/friends/"},{"categories":["faas"],"content":"1 FAAS 是什么 功能即服务 (FAAS) 是一类云计算服务，它提供了一个平台，允许客户开发、运行和管理应用程序功能，而 无需构建和维护通常与开发和启动应用程序相关的基础设施的复杂性。 构建遵循此模型的应用程序是实现“无服务器”体系结构的一种方式，通常在构建微服务应用程序时使用。 FAAS 最初是由 PiCloud 等各种初创企业在2010年左右提供的。 AWS Lambda 是大型公共云供应商提供的第一个 FAAS，随后是 Google Cloud Functions、Microsoft Azure Functions、IBM/Apache 2016年的 OpenWhisk (开源)和 2017 年的 Oracle Cloud FN(开源)。 国内的云厂商近几年也陆续提供 FAAS 产品，有阿里云 Serverless 服务、腾讯云云函数(Serverless Cloud Function，SCF)、华为云函数工作流（FunctionGraph）。 ","date":"2023-02-15","objectID":"/faas-notes/:1:0","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"1.1 FAAS 优点 降低运营成本，开发人员不需要对服务器根据流量做规划，将部署平台的能力外包； 降低开发成本，Serverless 是整个应用程序组件商品化的结果，将功能相似的函数解耦，统一提供服务，减少重复建轮子； 扩展成本，Serverless 的架构就是将部署环境外包，水平扩张是完全自动、有弹性，并且有提供方来支持管理的； 偶尔的请求，一些提供给运营人员的操作很低频； 不一致的流量，函数扩容速度远远大于容器扩容速度，高效响应突发流量带来的扩容问题； 运营管理更轻松 容器的租户管理使得研发人员无需关心部署系统； 降低打包和部署的复杂性； 专注于业务代码，更快的迭代与部署； ","date":"2023-02-15","objectID":"/faas-notes/:1:1","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"1.2 FAAS 缺点 控制权的转移，任何的外包策略，都会将部分的系统控制权移交到维护团队或组织，带来的就是不可控的系统停机、意外限制、成本变化、功能丧失、强制 API 升级等问题； 多租户问题，多个客户（租户）的多个软件在同一个机器上运行； 供应商锁定，一旦选择某个供应商或者维护团队，几乎是无法进行迁移的，代码的迁移大概率只能重构； 安全问题，会增加恶意攻击的剖面，增加攻击成功的可能性； 没有服务器内状态，持久化的数据无法在容器存储，只能借助第三方存储组件实现 cache； 测试问题，没有本地环境可以完全模拟云环境； 调试问题，云环境的调试目前还没有提供优秀的 tools； ","date":"2023-02-15","objectID":"/faas-notes/:1:2","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"2 业内 FAAS 的分支及发展 云服务商 产品 产品介绍 使用场景 客户案例 备注 AWS AWS Lambda AWS Lambda 是一项无服务器事件驱动型计算服务，该服务使您可以运行几乎任何类型的应用程序或后端服务的代码，而无需预置或管理服务器。 文件处理； 流处理；Web 应用程序；IoT 后端；移动后端； 可口可乐 西门子 Netflix Coinbase 阿里云 Serverless 工作流 Serverless 工作流（Serverless Workflow）是用来协调多个分布式任务执行的全托管 Serverless 云服务，简化开发、运行业务流程需要的任务协调、状态管理和错误处理等繁琐工作。用顺序、分支、并行等方式编排分布式任务，服务按照预设顺序协调任务执行，跟踪任务的状态转换，必要时执行用户定义的重试逻辑，确保工作流顺利完成。 多媒体文件处理场景；数据处理流水线场景；自动运维场景；解决运维无法可视化的问题； Serverless 应用引擎 SAE 是一个全托管、免运维、高弹性的通用 PaaS 平台。SAE 支持 Spring Boot、Spring Cloud、Dubbo、HSF、Web 应用和 XXL-JOB、ElasticJob 任务的全托管，零改造迁移、无门槛容器化、并提供了开源侧诸多增强能力和企业级高级特性。 微服务应用托管；弹性阔缩容场景；持续集成与交付； 贵州酒店集团 视野数科 爱奇艺体育 类似 side car ，用来管理应用，承接流量 Serverless 容器服务 ASK 是一款基于阿里云弹性计算基础架构，同时完全兼容 Kubernetes 生态，安全、可靠的容器产品。通过该产品，您无需管理和维护集群即可快速创建 Kubernetes 容器应用，并且根据应用实际使用的 CPU 和内存资源量进行按需付费，从而使您更专注于应用本身，而非运行应用的基础设施。 应用托管；在线业务弹性阔缩容数据计算 低成本支撑CI/CD任务执行 图森未来 越光医疗 腾讯云 云函数（Serverless Cloud Function，SCF） 腾讯云为企业和开发者们提供的无服务器执行环境，帮助您在无需购买和管理服务器的情况下运行代码。您只需使用平台支持的语言编写核心代码并设置代码运行的条件，即可在腾讯云基础设施上弹性、安全地运行代码。云函数是实时文件处理和数据处理等场景下理想的计算平台。 静态网站托管；构建 RESTful API；部署 Serverless 全栈 Web 应用；Serverless 全景录制方案； 腾讯视频 新东方 微信阅 腾讯教育 腾讯相册 百视通 猎豹移动 API网关 腾讯云 API 网关（API Gateway）是腾讯云推出的一种 API 托管服务，能提供 API 的完整生命周期管理，包括创建、维护、发布、运行、下线等。 Serverless HTTP；微服务整合；外部多端统一；业务整合；能力提供及售卖； 人人视频 江娱互动 腾讯视频 英孚教育 3 内部原理 ","date":"2023-02-15","objectID":"/faas-notes/:2:0","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"3.1 FAAS 方向 ","date":"2023-02-15","objectID":"/faas-notes/:3:0","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"3.1.1 运行架构 常规的一个服务在容器中启动的流程 FAAS 调用启动流程 在传统的服务启动或者是容器化的服务进行启动的是否，都是服务跟随者对应的平台（巨石架构的物理机器或者微服务化的 k8s 容器）的启动而启动，整个生命周期在 pod 的启动开始，在 pod 的关机下线操作结束，整个周期是比较长的，同时必须有实例存活（至少一台）来承接响应，研发人员除了需要关注自己的开发 code，还需要关注容器的大小、容量、数量等运维指标； Serverless 中的 FAAS 将研发人员最重要的业务逻辑抽离了出来，除了这部分需要去管理升级，剩下的都交由 FAAS 提供平台来提供服务，托管后的 FAAS 生命周期从 pod 的启动关机简化到了 执行函数 handler 的 init 以及执行函数时间，并且在一些低频的业务中，一些函数实例可以交由 FAAS 提供服务商进行回收，甚至在某些时间不起函数实例，当有事件进来之后在执行函数初始化及执行逻辑（因为函数初始化到可以服务的启动时间在 100ms 左右，当然不同语言以及不同的服务提供方的实现会影响这里的启动时间）； ","date":"2023-02-15","objectID":"/faas-notes/:3:1","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"3.1.2 架构分层 其实理解起来比较简单，可以理解成我们的代码已经是与 PAAS 平台进行强解耦的结果了，我们的代码就是一部电视剧，一个操作系统安装了指定的视频播放器就可以播放我们的电视剧了，同理，我们现在只需要关心我们的函数内业务代码逻辑的定义，只要接口定义的按照封装平台的要求来开发即可，我们不需要关心运行的环境及系统，由于 runtime 已经到了 func 级别，热更新代码以及启动服务都是快速可以响应的。 ","date":"2023-02-15","objectID":"/faas-notes/:3:2","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"3.2 Mesh 方向 综上，若 FAAS 代表着是“无服务器”架构的话，其实 Service Mesh 严格意义上不能称为是“无服务器”架构，它并不能将容器部署与代码部署隔离开，只是在服务响应中增加了一层代理，用来控制应用程序中服务请求的传递，可以使得服务到服务的通讯快速、可靠和安全。 ","date":"2023-02-15","objectID":"/faas-notes/:4:0","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"3.2.1 运行架构 优点： 简化微服务和容器中服务之间的通信； 更容易的诊断通讯错误，发生在自己的基础设施层上； 支持加密、认证和授权等安全特性； 允许更快地开发、测试和部署应用程序； 放置在容器集群的边车代理可以有效的管理网络服务； 缺点： 运行时实例通过使用服务网格而增加； 每次服务的调用都要经过 sidecar proxy； 没有解决与其他服务或者系统的集成，以及路由类型或转换的映射； 网格管理的复杂新被抽象化和集中化； ","date":"2023-02-15","objectID":"/faas-notes/:4:1","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"3.2.2 架构分层 将调用限流、熔断、安全、服务注册与发现、服务管理等非业务逻辑的功能全部都放到 Sidecar 中去，本质上是一个管理性质进程在管理着业务逻辑性质的进程，进程之间的通讯使用的是 UDC(Unix domain socket)。 ","date":"2023-02-15","objectID":"/faas-notes/:4:2","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["faas"],"content":"4 Reference https://en.wikipedia.org/wiki/Function_as_a_service https://serverless.aliyun.com/ https://cloud.tencent.com/product/scf https://www.huaweicloud.com/product/functiongraph.html https://martinfowler.com/articles/serverless.html https://aws.amazon.com/cn/lambda/ https://time.geekbang.org/column/article/226574 https://www.techtarget.com/searchitoperations/definition/service-mesh https://www.zhaohuabing.com/2018/03/29/what-is-service-mesh-and-istio/ ","date":"2023-02-15","objectID":"/faas-notes/:5:0","tags":["faas","notes","serverless"],"title":"FAAS 调研笔记","uri":"/faas-notes/"},{"categories":["financing"],"content":"办理港卡之后，在证券市场找到了一款注重用户交互的证券 APP（长桥证券 APP），使用体验是大家常用港美股证券 APP 中最好的，活动期间通过专属链接注册开户，可以申请港美股终身免佣，推荐大家使用，投资港美股主要就是港卡比较难办，现在长桥与两个银行搞团办活动，大家感兴趣的可以办理注册下，另外现在入金还有奖励，办理好港卡和银行账户，就可以投资港美股了，就可以做世界 Top 公司的股东了。当然要牢记股市有风险，投资需谨慎，理性投资。 ","date":"2023-02-12","objectID":"/financing-long-bridge/:0:0","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"1 注册长桥 ","date":"2023-02-12","objectID":"/financing-long-bridge/:1:0","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"2 办理港卡 准备办卡资料；ps 小米同学建议优先选择民生。 北京民生团办时间：2.21 - 2.24 北京南洋团办时间：暂未确定，火热报名中，预计 3 月底 动态更新 ","date":"2023-02-12","objectID":"/financing-long-bridge/:2:0","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"2.1 民生香港办卡资料 身份证 + 护照（有效期大于 6 个月）； 任意国家多次往返签证； 员工工牌，实体卡； 现场会开民生内地卡，需转入 5w 人民币保留 3 个月后可提取； ","date":"2023-02-12","objectID":"/financing-long-bridge/:2:1","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"2.2 南洋香港办卡资料 身份证 + 护照（有效期大于 6 个月）； 任意国家多次往返签证； 现场会开南洋内地卡，需转入 1w 人民币，下卡可提取； ","date":"2023-02-12","objectID":"/financing-long-bridge/:2:2","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"2.3 签证渠道 如无签证，可淘宝搜索尼泊尔签证，选择销量高的店铺，选择单次停留90天，180天有效期（一般是99元）。 注意：办卡信息和服务由银行提取，长桥不收取任何费用。 ","date":"2023-02-12","objectID":"/financing-long-bridge/:2:3","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"3 入金活动 ps. 根据不同月份活动动态更新。 长桥 2 月开工福利送不停！ ","date":"2023-02-12","objectID":"/financing-long-bridge/:3:0","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"3.1 开户福利 开户可享港股免佣福利、长桥现金打新免费（新老客户）、100 港币股票现金卡、新客专享美元货币基金，年化收益 4.65% 左右，资金不浪费。 ","date":"2023-02-12","objectID":"/financing-long-bridge/:3:1","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"3.2 新用户入金 2w 港币福利 600 港币股票现金卡 + 400 港币平台费抵扣卡； 两人拼团，每人额外再送 200 京东卡； 入金 30 天内交易一次美股期权，再送 200 港币股票现金卡； 港股终身免佣； ","date":"2023-02-12","objectID":"/financing-long-bridge/:3:2","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["financing"],"content":"4 企业认证 如果你是可支持认证的企业员工的话，建议做一下企业认证，一般有企业邮箱的话直接输入邮箱账号接收验证码就可以完成认证了，企业认证后有需要优惠活动。 ","date":"2023-02-12","objectID":"/financing-long-bridge/:4:0","tags":["证券","长桥","港美股","longbridge"],"title":"长桥港美股团办活动","uri":"/financing-long-bridge/"},{"categories":["summary"],"content":"今年，时光依旧不饶人，步入社会以来，时间就似乎不会慢下来，都在光速飞逝，很遗憾，今年疫情依旧没有结束，3 月份的时候还作为密切接触者被隔离了 21 天，总的来说，今年有悲伤同时又十分幸运，感觉冥冥之中都是安排好的。 ","date":"2022-12-31","objectID":"/debuginn-2022/:0:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"网站数据 2022年统计数据共享链接 ","date":"2022-12-31","objectID":"/debuginn-2022/:1:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"摄影专区 今年为了兴趣爱好买了一台微单 索尼 α6400+18135 镜头，同时，也想着把自己的摄影作品呈现给大家，每年我都会更新一批图片到这里，选 10 张自己认为比较好的图片拿来展出，水平不高，但是每一张照片背后都有属于它的专属意义。直达链接 ","date":"2022-12-31","objectID":"/debuginn-2022/:2:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"年度事件 ","date":"2022-12-31","objectID":"/debuginn-2022/:3:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"疫情 有感动有奇迹 记得在 3 月份的某一天，突然接到领导通知，大家全体居家办公，具体情况听通知，不得外出，下午就接到了确认密接的防疫办的电话，让在家等着去集中隔离，由于密接人数比较多，第二天下午才安排到酒店隔离，一切安排都没有那么混乱，大家都有序进行隔离入住，庆幸的是，隔离的地方还不错，至少可以安心的在隔离期间办公了，隔离期间还下了一场雪，别有一番风景。 隔离期间，大家互相勉励，配合大白检测，大家都很有信心，隔离结束之后，得知大家作为密接都没有被感染 😷，像是一个奇迹，大家都好好滴，同时也传来了确诊同事阳转阴的好消息。 回头想来，这次防疫应该是北京政府做的一轮比较优秀的防疫案例了，做到了透明、快且安全。 ","date":"2022-12-31","objectID":"/debuginn-2022/:3:1","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"是的 我们就这样相遇了 都说红螺寺和雍和宫很灵验，去寺院诚心叩拜了每一个佛祖菩萨，感谢佛祖菩萨，的确如此，是的，我们就这样相遇了，新的一年和她，真好。 新的一年，我们的故事正在续写～ 我坚信真诚的对待感情总会有好的结果，感谢相遇，感谢这神奇的缘分～ ps：不过多介绍，还有下文哦～ ","date":"2022-12-31","objectID":"/debuginn-2022/:3:2","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"是的 我成杨过了 12月17号在喉咙疼了好几天的情况下，最后还是测量的体温在 38.5 度，我已经感觉中招了，不出意外，接下来连续三天都持续高烧，浑身上下疼痛，之后还流鼻血，应该是高烧烧的，之后就是居家躺尸阶段，没有精神同时伴随有轻微咳嗽，后来做了抗原检测，果然中招，不过目前好了。大家注意防护与提高自身免疫力，很重要的。 ","date":"2022-12-31","objectID":"/debuginn-2022/:3:3","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"好物分享 摄影设备：微单 索尼 α6400+18135 镜头； 键鼠套装：Mac 新一代键盘、触控板套装； 显示设备：目前主力生产使用的 LG HDR 4k 显示器； 辅助灯光：目前使用的是小米屏幕挂灯 1s，搭配米家使用非常流畅； 充电设备：小米无线充电宝+座充底座，既可以室内充当无线充电，又可以户外活动使用； ","date":"2022-12-31","objectID":"/debuginn-2022/:4:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"年度书籍 今年算是奋起阅读的一年了，短短三个月时间就啃下来很多书，很有营养，以后也要给自己补补能量，让自己变得更强。 技术 《Effective Go 中英双语版》bingo，很棒的一本 Go 入门数据； 公司 《一往无前》范海涛，讲解公司创立到十周年发生的故事; 小说 《黄金时代》王小波，自由？背叛？性？ 读完没有啥感觉； 散文 《乖，摸摸头》大冰，第二次读，算是疫情三年禁锢肉体的另一种解脱； 技术 《图解 HTTP》上野，用通俗易懂的漫画讲解； 技术 《分布式缓存：原理、架构及Go语言实现》胡世杰，讲的很透彻，数据提供的很透彻； 技术 《深入理解Java虚拟机JVM高级特性与最佳实践》周志明，java 进阶书籍，值得推荐； 技术 《深入设计模式》，设计模式算是 code 中让房子长什么样的设计方法论了； 散文 《保重》大冰，没有读完，算是给自己的青春留下一章吧，保重； ","date":"2022-12-31","objectID":"/debuginn-2022/:5:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"年度文章 本年度很懒，没有出啥文章，就写了两篇，那就算作年度文章吧～ Go 语言学习进阶之路 https://www.debuginn.cn/7402.html 使用 pprof 对 Go 程序进行分析优化 https://www.debuginn.cn/7444.html ","date":"2022-12-31","objectID":"/debuginn-2022/:6:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"Github 个人页面 今年倾心打造自己的技术主页，术业有专攻，对自己在技术专业能力方面在 23年有更高的要求，同时希望自己在技术圈可以成为有影响力的人，来帮助更多的同行，同时也在不断的提升自己，直达链接。 ","date":"2022-12-31","objectID":"/debuginn-2022/:7:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["summary"],"content":"总结 这一年总的来说是给自己带来很大成长的一年，褪去了年少的青涩，增加了一点成熟的模样，也懂得了珍惜当下，活好每一天，爱人爱己，学会了倾听、学会了表达、学会了接受失去、同时也学会了迎接未来，感恩、感谢、感激、感动，这就是我的 2022年。 2023年，祝大家新年快乐， happy new year ～ ","date":"2022-12-31","objectID":"/debuginn-2022/:8:0","tags":["Debug客栈","2022","2023","年度总结"],"title":"2022 年度总结","uri":"/debuginn-2022/"},{"categories":["golang"],"content":"前言 在生产环境中，偶尔会发生 Go 程序 CPU 暴增的现象，排除某时段并发大的场景外，通过监控面板看不到程序是因为什么原因导致的，Go 语言原生就提供了工具 pprof，Google 对于 pprof 的解释就是一个用于可视化和分析数据的工具。 通过使用 Go pprof 可以对程序的 CPU性能、内存占用、Goroutine wait share resource、mutex lock 做剖面分析，我们可以使用该工具收集运行时的程序性能指标，从而分析出程序中是否由于代码编写不合理导致存在不合理的资源占用情况，从而对程序进行优化用来提升其性能。 ","date":"2022-05-01","objectID":"/go-tools-pprof/:1:0","tags":["Go","pprof","分析","go pprof","go tools"],"title":"使用 pprof 对 Go 程序进行分析优化","uri":"/go-tools-pprof/"},{"categories":["golang"],"content":"功能 Go pprof 提供了以下五种不同维度观测其程序的功能： CPU Profiling：CPU 性能分析，按照指定时间采集监听其 Go 程序 CPU 的使用情况，可以确定 Go 程序在哪个程序段中占用 CPU 耗时长； Memory Profiling：内存性能分析，用来分析程序的内存堆栈区使用情况，用来检测是否存在内存泄漏； Block Profiling：Goroutine 等待共享资源阻塞分析； Mutex Profiling：互斥锁分析，用来报告共享资源使用互斥锁的竞争的情况； Goroutine Profiling：协程性能分析，用来报告对当前运行时的 Goroutine 操作及数量。 ","date":"2022-05-01","objectID":"/go-tools-pprof/:2:0","tags":["Go","pprof","分析","go pprof","go tools"],"title":"使用 pprof 对 Go 程序进行分析优化","uri":"/go-tools-pprof/"},{"categories":["golang"],"content":"使用 Go pprof 工具的使用也是比较简单快捷的，可以使用runtime/pprof包生成一个 profile 文件，网上也有很多的教程，这里不再过多描述了，详细可以看下包提供的函数，上面介绍了使用方法。 目前我们主要使用的是net/http/pprof包，启动一个独立端口号 http 程序单独用来 Go 程序的分析，搭配着 graphviz 组件来可视化程序来分析数据，使用起来也是比较方便的： 第一步，将net/http/pprof包引用到程序中，建议直接放在程序入口处 main.go 文件 import ( _ \"net/http/pprof\" ) 第二步，若本身是一个 http 的程序，不需要此步骤，若不是 http web 程序或者不想将对应信息暴露在外网，可以单开一个 http web 程序用来专门监听服务： func main() { // 程序逻辑代码 go func() { _ = http.ListenAndServe(\":8848\", nil) }() } 第三步，运行主程序，访问 pprof 界面： http://127.0.0.1:8848/debug/pprof/ # 主界面 http://127.0.0.1:8848/debug/pprof/allocs # 所有过去内存分配的采样 http://127.0.0.1:8848/debug/pprof/block # 导致同步阻塞的堆栈跟踪 http://127.0.0.1:8848/debug/pprof/cmdline # 当前程序的命令行的完整调用路径 http://127.0.0.1:8848/debug/pprof/goroutine # 所有当前 Goroutine 的堆栈跟踪 http://127.0.0.1:8848/debug/pprof/heap # 活动对象的内存分配的采样 http://127.0.0.1:8848/debug/pprof/mutex # 争用互斥锁持有者的堆栈跟踪 http://127.0.0.1:8848/debug/pprof/profile # CPU 配置文件 http://127.0.0.1:8848/debug/pprof/threadcreate # 创建新 OS 线程的堆栈跟踪 http://127.0.0.1:8848/debug/pprof/trace # 当前程序执行的跟踪 后缀加上 ?debug=1 可以可视化查看对应描述，不加就可以下载成 profile 文件，使用 pprof 命令可视化查看对应数据。 第四步，使用 go tool pprof -http=:6001 profile 命令查看分析程序。 ","date":"2022-05-01","objectID":"/go-tools-pprof/:3:0","tags":["Go","pprof","分析","go pprof","go tools"],"title":"使用 pprof 对 Go 程序进行分析优化","uri":"/go-tools-pprof/"},{"categories":["golang"],"content":"分析 上图是针对 CPU 使用做的采集可视化，箭头越粗、方块越大就代表着对应的操作消耗 CPU 大，可以看到占用 CPU 最多的操作就是 json 的序列化和反序列化操作。 同理对应的内存性能、Goroutine 阻塞的分析都可以看出对应的操作。 ","date":"2022-05-01","objectID":"/go-tools-pprof/:4:0","tags":["Go","pprof","分析","go pprof","go tools"],"title":"使用 pprof 对 Go 程序进行分析优化","uri":"/go-tools-pprof/"},{"categories":["golang"],"content":"总结 使用 go pprof 工具可以分析解剖程序运行性能问题，可以快速定位生产环境中遇到的问题，并作出优化或者 fix bug，最后祝大家不会写出 bug code，程序稳定、头发永在。 ","date":"2022-05-01","objectID":"/go-tools-pprof/:5:0","tags":["Go","pprof","分析","go pprof","go tools"],"title":"使用 pprof 对 Go 程序进行分析优化","uri":"/go-tools-pprof/"},{"categories":["summary"],"content":"今年，时间依旧飞快流逝，转眼间，自己已经毕业了小2年了，渐渐的自己开始习惯了北漂的生活，一个人的北京，自由与孤独同在。也体会到了离家远的遗憾，远的连奶奶最后一面也没有见到，第一次感受到了亲人阴阳两隔的无奈与悲哀。疫情 😷 在全球范围内还在持续，国内偶尔也零星的出现，但愿 22 年疫情结束，全世界人们都可以回归到疫情之前，和爱人、亲人、朋友去想去的地方，去探索多彩的世界。 ","date":"2021-12-30","objectID":"/debuginn-2021/:0:0","tags":["Debug客栈","2021","2022","年度总结"],"title":"2021 年度总结","uri":"/debuginn-2021/"},{"categories":["summary"],"content":"网站数据 2021年统计数据共享链接 今年，写了一些在工作中使用到的 Golang 的一些技巧及思考，以及一些规范。 让我意外的是大家对 Go 语言入门学习有着很大的兴趣，下面这个文章是今年访问最多的文章，访问量：2785 Go 语言开发设计指北 https://www.debuginn.cn/6832.html ","date":"2021-12-30","objectID":"/debuginn-2021/:1:0","tags":["Debug客栈","2021","2022","年度总结"],"title":"2021 年度总结","uri":"/debuginn-2021/"},{"categories":["summary"],"content":"技术导航 经常游荡于各个大厂的技术博客之中，于是做了一个集合导航，后续计划将大佬们也收集到此，大家有好的技术分享网站也可以评论区留言分享一下。 大厂技术栈 https://www.debuginn.cn/tech ","date":"2021-12-30","objectID":"/debuginn-2021/:2:0","tags":["Debug客栈","2021","2022","年度总结"],"title":"2021 年度总结","uri":"/debuginn-2021/"},{"categories":["prometheus"],"content":"近期，我们对 APP 网关 Gateway 做了升级，由于项目创建时间过早（6年前的项目），那时候还没有好的包管理工具，使用的是最原始的 Go Path 来进行项目的依赖管理，历史包袱比较重，项目中很多的第三方引用都是直接将代码拷贝到项目目录下，升级与维护起来特别麻烦，升级之后就是现在官方主推的是 Go module 包管理方式。 解决了上面的这个痛点，网关程序就可以集成一些业界主流的基础工具，升级与维护起来就简单多了。 言归正传，本文主要是讲的我们是如何用 Prometheus 对网关进行监控的，之前我们的网关程序也是集成了我们公司开源打点监控工具 Open falcon，并且使用 Grafana 进行绘图并查看，但是为啥我们不再继续使用了？之后我们为啥拥抱了 Prometheus 生态？还有一些打点、报警、绘图的思考，还有一些我们在使用的过程中出现的问题以及解决方案，一一讲解一下。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:0:0","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"抛弃 Open falcon 拥抱 Prometheus 在决定使用 Prometheus 之前，我们的 Gateway 使用的是 Open falcon，但是一直存在着一个对于我们而言的痛点，就是作为网关程序，历史维护的路由太多了，接口可用性及接口报错无法聚合报警，也就是我们的监控体系存在着盲区，这个对我们而言来说是最为致命的，那个接口出现了问题会直接导致用户的使用，并且我们使用的那些上游服务出现问题我们也无法及时感知。 使用 Prometheus 最主要的是我们可以通过 PromQL 语法进行正则匹配，实现对某个或多个接口的聚合计算并报警，这样就可以解决我们无法聚合报警的一个痛点。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:1:0","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"打点、绘图、报警 ","date":"2021-12-11","objectID":"/prometheus-gateway/:2:0","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"打点 全面、量小 作为业务使用，怎么设计点位，既可以满足报警使用，对每个接口进行各项指标的监控，同时要保证点位数据是可穷举的（避免出现 OOM）和产生数据量比较小。简而言之，就是“监控要全面、打点数据量要小”，因为数据量大的话在 Prometheus 拉取指标的时间及周期就不得不设置的过大，这样的后果就是造成图的绘制缓慢甚至超时，同时报警也失去了实效性。 我们网关使用的是 http 协议，可以充分利用 Go 的 net/http 特性，使用中间件设计，对请求与返回进行打点，于是我们是这样设计的： 对任意一个请求做一个 qps 的打点记录（无任何的业务参与其中）； 对单个路由请求进行打点（区分业务状态码）； 对单个路由请求进行耗时打点（区分业务状态码）。 请求路由按照业界通用的设计：/version/model/action 以上的场景，仅仅使用指标类型中的两种 Counter（计数器） 和 Histogarm（直方图）就可以满足我们打点需求。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:2:1","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"绘图 清晰、快速 构建一栋房子所需的材料都准备好了，准备建造， building…… 点位指标收集到了，接下来就是对点位进行各个维度的拼装，来呈现我们想要的图，这里解答一下为什么我们要把业务状态码打到指标中去，以及我们是如何使用的：我们的系统设计采用业务封装错误码，只要是传输调用链路没有问题，所有的场景都走业务状态码，类似的返回解决如下： { \"code\": 0, \"desc\": \"success\", \"data\":{ \"result\": \"ok\" } } code 为 0，代表当前请求是正常的，返回数据会封装在 data 中； code 不为 0，代表着当前请求存在业务上可捕获或者自定义的错误。 作为网关程序，与下游微服务采用相同的接口设计，对我们现在的打点设计也是非常友好的。 同样的，有的服务使用的是 Restful API 思想，使用的是 http 标准状态码，那就是 200 代表着成功，非 200 代表着业务或者系统存在错误，当然 5XX 错误可以单独拿出来做可用性或者细化的报警。 之所以打点记录业务状态码，好处如下： 对业务状态码打点，可以对某个业务上的特定错误进行捕捉，看图及报警都是非常便捷的； 不影响对接口可用性进行计算，可以多维度聚合计算可用性（根据业务定义而言）。 当然，打点指标设置的粒度越小，对应的点位的存储大小以及聚合运算的代价也是成倍的提高的。 铺垫了好久，说一下我们是怎么进行绘图的，在打点的时候讲到使用 Counter、Histogram 进行打点，绘图的时候我们主要从以下三点进行可视化： 接口的 qps 看图呈现； 接口可用性（Pxx）看图呈现； 接口请求PXX 耗时统计 看图呈现。 接口 qps 看图绘图 qps 的点位数据怎么打？就是充分利用中间件的设计，在一个请求 prepare 阶段就将该路由记录并获取进行打点。 使用 PromQL 语句就可以实现对对应信息看图的绘制。 // 过去1分钟 每秒请求 qps // sum 求和函数 // rate 计算范围向量中时间序列的每秒平均增长率 // api_request_alert_counter 指标名称 // service_name 和 subject 都是 label kv参数 sum(rate(api_request_alert_counter{service_name=\"gateway\", subject=\"total\"}[1m])) by (subject) 接口可用性看图绘图 接口可用性就是验证当前接口在单位时间内的处理正确的请求数目比上总体的请求数目，在打点的时候也讲到，我们业务代码 0 代表着正确返回，非 0 的代表着存在问题，这样就可以很简单的算出来接口的可用性。 // 过去1分钟 每秒接口可用性 // sum 求和函数 // rate 计算范围向量中时间序列的每秒平均增长率 // api_request_cost_status_count 指标名称 // service_name 和 code 都是 label kv参数 (sum(rate(api_request_cost_status_count{service_name=\"gateway\", code=\"0\"}[1m])) by (handler) / ( sum(rate(api_request_cost_status_count{service_name=\"gateway\", code=\"0\"}[1m])) by (handler) + sum(rate(api_request_cost_status_count{service_name=\"gateway\", code!=\"0\"}[1m])) by (handler)) ) * 100.0 接口 Pxx 耗时统计看图绘图 接口耗时统计打点依赖 prometheus api 中的 histogram 实现，在呈现打点耗时的时候有时候局部的某个耗时过长并不能进行直接反应整体的，我们只需要关注 SLO （服务级别目标）目标下是否达标即可。 // 过去1分钟 95% 请求最大耗时统计 // histogram_quantile 1000* histogram_quantile(0.95, sum(rate(api_request_cost_status_bucket{service_name=\"gateway\",handler=~\"v1.app.+\"}[1m])) by (handler, le)) histogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数（百分位数的一般形式）的样本的最大值。（有关 φ 分位数的详细说明以及直方图指标类型的使用，请参阅直方图和摘要）。向量 b 中的样本是每个 bucket 的采样点数量。每个样本的 labels 中必须要有 le 这个 label 来表示每个 bucket 的上边界，没有 le 标签的样本会被忽略。直方图指标类型自动提供带有 _bucket 后缀和相应标签的时间序列。 上面是官方对于 histogram_quantile 函数的解释，关注的是 设置 φ 分位数 对应的 bucket 桶，但是实际中有 分位数计算误差的问题。 Prometheus 官方 histogram 设置的默认 buckets 如下： DefBuckets = []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10} 这里可以看到我们的接口指标分界时间，每一个请求的耗时都会根据具体的设置的 buctet 的范围落到不同的区间内，这里设置的桶的范围直接影响到计算值的准确度（上面所提到的 分位数计算误差问题）。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:2:2","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"报警 及时、准确 使用 Prometheus 的 Alert Manager 就可以对服务进行报警，但是如何及时又准确的报警，已经如何合理设置报警，我们就要引入 SLO 的概念，在实际的业务场景中，我们会发现某个接口某个时间段的耗时是一组离散的点： 我们可以看到大部分的请求可以在 1s 之内就可以快速的返回，只有个别的请求可能由于网络的抖动、应用短暂升级或者其他因素导致过慢，若是我们直接设置接口最大请求耗时超过2s（持续一个时间段），那我们就面临着疯狂的告警轰炸，同时告警也就失去了针对某个接口的异常活动做出提示供开发人员处理的意义。 服务级别目标（Service-level objective，SLO）是指服务提供者向客户作出的服务保证的量化指标。服务级别目标与服务级别协议有所不同。服务级别协议是指服务提供者向客户保证会提供什么样的服务，服务级别目标则是服务的量化说明。 Service-level objective 服务级别目标 比方说我们发现上面的 90% 请求都在 1s 内返回，我们就可以只需要对 90% 请求耗时做监控分析其调用链路并告警。 举个栗子，比方说我们一个首页的接口 /v1/home/page 99% 的请求可以在 500ms 内返回，只有个别的请求超过 2s+ 的时间，大多数情况下我们就不会关心这 1%的请求，那我们就可以定制一个 持续 1分钟首页 99% 请求耗时大于 1s的报警，这样当我们收到报警的时候，我们就可以第一时间知道首页出现了问题，我们就可以根据报警及时处理。 **业务的报警是与接口的实现与调用链路的复杂度是紧密结合在一起的，根据不同的业务场景，配置合理的报警才满足我们及时准确的要求。**反之就是配置过高不灵敏、往往线上已经出现了好久报警就是没有，配置过低，分分钟触发报警，对业务开发人员增加了排查问题的时间成本。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:2:3","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"遇到的问题 ","date":"2021-12-11","objectID":"/prometheus-gateway/:3:0","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"收集指标过大拉取超时 由于我们是 gateway BFF 层做得指标，本身的路由的基数就比较大，热点路由就有好几百个，再算上对路由的打点、耗时、错误码等等的打点，导致我们每台机器的指标数量都比较庞大，最终指标汇总的时候下游的 prometheus 节点拉取经常出现耗时问题。 前期解决方案比较粗暴，就是修改 prometheus job 的拉取频率及其超时时间，这样可以解决超时问题，但是带来的结果就是最后通过 grafana 看板进行看图包括报警收集上来的点位数据延迟大，并且随着我们指标的设置越来越多的话必然会出现超时问题。 目前的解决方案就是做分布式，采用 prometheus 联邦集群的方式来解决指标收集过大的问题，采用了分布式，就可以将机器分组收集汇总，之后就可以成倍速的缩小 prometheus 拉取的压力。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:3:1","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"动态收集机器指标 因为我们机器都是部署在集群上并且会随着活动大促动态调整机器的数量，联邦集群中配置文件最重要的就是配置各个收集节点指标的 IP:Port ，我们不可能每次都去手动维护这个配置，成本比较高，那么我们就需要将配置动态写入，针对此问题，在 leader 的建议下，使用运维服务树拿到该节点下的机器的 Ip，使用脚本程序动态维护起来就非常方便了，默认 Prometheus 是 20s 读取一次配置。 ","date":"2021-12-11","objectID":"/prometheus-gateway/:3:2","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"请求的耗时看图与报警不准确 这个问题是在我们的业务中，请求耗时最常见的是在 2s 之内返回，但是通过 Prometheus histogram 对应 1-2s 的请求会落在 le 为 2.5 桶中，导致报警误报，我们看日志中的请求在 1.* s 的都算在 2.5 的桶上，而报警的配置是 大于 2s， emmm DefBuckets = []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10} 之后根据我们的业务场景调整了一下，使用了自己的 CustomBuckets： CustomBuckets = []float64{.01, .025, .05, .1, .25, .5, 1, 1.5, 2, 3, 4, 8} ","date":"2021-12-11","objectID":"/prometheus-gateway/:3:3","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["prometheus"],"content":"References Prometheus 官方文档 Prometheus 翻译文档 wiki SLO 服务级别目标 wiki 累积直方图 ","date":"2021-12-11","objectID":"/prometheus-gateway/:4:0","tags":["prometheus","grafana","open falcon","counter","histogram"],"title":"我们是如何用 Prometheus 对网关进行监控的","uri":"/prometheus-gateway/"},{"categories":["job"],"content":" 永远相信美好的事情即将发生 欢迎大家联系我，让我为你内推吧，小米众多岗位等你来选，不清楚岗位信息的可以联系我，我会给你发对应的内推部门及岗位，也可以联系我查询内推情况，感觉OK，你就来吧！ ","date":"2021-09-23","objectID":"/mi-work/:0:0","tags":["内推"],"title":"来小米，一起玩 ！！！","uri":"/mi-work/"},{"categories":["git"],"content":"前言 在团队开发中，使用 Git 作为版本开发工具，可以便捷地协同多人管理并行开发，但是由于自己或者其他人代码提交污染了远程分支，就需要对远程代码进行恢复操作，Git 提供了 reset 和 revert 两种命令来进行恢复操作，这两种操作效果是截然不同的，不太清楚这个原理的同学需要了解一下，以免在实际的开发过程中翻车，导致线上远程仓库不可逆转的操作。 首先从英文释义来讲，reset 是重置的意思，revert 是恢复、还原的意思，作为 Coder ，第一感觉 reset 的效果比 revert 更猛一些，实际情况也的确如此，让我们一起探讨一下吧。 ","date":"2021-09-21","objectID":"/git-reset-revert/:1:0","tags":["git","github","reset","revert"],"title":"Git 命令 reset 和 revert 的区别","uri":"/git-reset-revert/"},{"categories":["git"],"content":"背景 Git 的每一次提交都是一次 commit，上图可以看到在时间线上有三次提交，此时 HEAD 指向 main 分支，main 分支又指向最新的 Commit3。 HEAD 是指向当前分支的最新提交的指针，可以在任意分支进行切换； main （master）分支，是一个 git 代码仓库的主分支也是默认分支； commit 每一次提交代码都会产生一个 commit id 来标识工作区的变更与改动。 ","date":"2021-09-21","objectID":"/git-reset-revert/:2:0","tags":["git","github","reset","revert"],"title":"Git 命令 reset 和 revert 的区别","uri":"/git-reset-revert/"},{"categories":["git"],"content":"实践出真理 为了直接明白的了解其原理，我这里在 github 上创建一个空白的仓库，按照上图创建三次提交： commit b0ef8f9125226af8f06ff1aba7c1f1fc83adea9b (HEAD -\u003e master, origin/master) Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:36:39 2021 +0800 feat add 3.go commit 338bf3e30983d34074f37a18b3ff80ea9bca75f0 Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:36:09 2021 +0800 feat add 2.go commit 6b166ed34962da08d944e2b1d3f36d9015dd8f35 Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:35:16 2021 +0800 feat add 1.go ","date":"2021-09-21","objectID":"/git-reset-revert/:3:0","tags":["git","github","reset","revert"],"title":"Git 命令 reset 和 revert 的区别","uri":"/git-reset-revert/"},{"categories":["git"],"content":"Git Reset git reset 的作用是将 HEAD 指向指定的版本上去： 1 使用 git log 查看提交记录： commit b0ef8f9125226af8f06ff1aba7c1f1fc83adea9b (HEAD -\u003e master, origin/master) Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:36:39 2021 +0800 feat add 3.go commit 338bf3e30983d34074f37a18b3ff80ea9bca75f0 Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:36:09 2021 +0800 feat add 2.go commit 6b166ed34962da08d944e2b1d3f36d9015dd8f35 Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:35:16 2021 +0800 feat add 1.go 这里可以看到我们提交了三次记录，我们现在想恢复到第一次 commit 提交的时候。 2 使用 git reset –hard 命令操作： ➜ demo git:(master) git reset --hard 6b166ed34962da08d944e2b1d3f36d9015dd8f35 HEAD 现在位于 6b166ed feat add 1.go 再次查看 git log : commit 6b166ed34962da08d944e2b1d3f36d9015dd8f35 (HEAD -\u003e master) Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:35:16 2021 +0800 feat add 1.go 此时我们可以看到已经恢复到了第一次提交代码的时候，目前我们是使用 git reset --hard 的方式，其实这里存在着三种方式，TODO 下一篇 git 操作讲一下。 这时候我们只是讲本地的 HEAD 指向了 main 分支的 commit 1，但是远程并没有变更，此时需要强行推一下就可以了。 3 使用git push -f 强行推送到远程： ➜ demo git:(master) git push -f 总共 0（差异 0），复用 0（差异 0），包复用 0 To github.com:debuginn/demo.git + b98f95e...6b166ed master -\u003e master (forced update) 此时我们可以看到远程也没有了我们之前提交的三次记录而是只有第一次的提交记录。 警告 在团队合作的共同操作一个仓库的时候， git reset 命令一定要慎重使用，在使用的时候一定要再三确认其他同学的代码是否会被重置操作而导致代码丢失，导致一些提交记录的丢失，这些都是不可逆的，一定要慎重。 ","date":"2021-09-21","objectID":"/git-reset-revert/:3:1","tags":["git","github","reset","revert"],"title":"Git 命令 reset 和 revert 的区别","uri":"/git-reset-revert/"},{"categories":["git"],"content":"Git revert git revert 是用来重做某一个 commit 提交的内容，在我们原始的提交之中，我们会发现分支上面有创建了一个新的 commit 提交，而此时我们对于想重做的某个 commit 提交的内容都不存在了： 1 使用git log查看提交记录： Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 16:36:39 2021 +0800 feat add 3.go 2 使用git revert命令重做操作： ➜ demo git:(master) git revert 338bf3e30983d34074f37a18b3ff80ea9bca75f0 删除 2.go [master ef822b7] Revert \"feat add 2.go\" 1 file changed, 9 deletions(-) delete mode 100644 2.go 再次查看 git log : commit ef822b71c33a2dbbdaa350fddcfa14e8fc55e543 (HEAD -\u003e master, origin/master) Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 17:12:00 2021 +0800 Revert \"feat add 2.go\" This reverts commit 338bf3e30983d34074f37a18b3ff80ea9bca75f0. commit b0ef8f9125226af8f06ff1aba7c1f1fc83adea9b Author: debuginn \u003cdebuginn@icloud.com\u003e Date: Tue Sep 21 17:05:39 2021 +0800 feat add 3.go 可以看到当前已经重做了一下 commit 2 的提交，已经讲 2.go 删除掉了。 可以看到 github 上面有了四次提交记录。 ","date":"2021-09-21","objectID":"/git-reset-revert/:3:2","tags":["git","github","reset","revert"],"title":"Git 命令 reset 和 revert 的区别","uri":"/git-reset-revert/"},{"categories":["git"],"content":"总结 git reset和git revert都是属于重新恢复工作区以及远程提交的方式，但这两种操作有着截然不同的结果： git reset是将之前的提交记录全部抹去，将 HEAD 指向自己重置的提交记录，对应的提交记录都不复存在； git revert 操作是将选择的某一次提交记录 重做，若之后又有提交，提交记录还存在，只是将指定提交的代码给清除掉。 选择合适的方式回滚自己的代码在团队合作中很重要，但是要慎重操作，不要丢失代码哦。 ","date":"2021-09-21","objectID":"/git-reset-revert/:4:0","tags":["git","github","reset","revert"],"title":"Git 命令 reset 和 revert 的区别","uri":"/git-reset-revert/"},{"categories":["coin"],"content":"今天使用数字人民币兑换了建党100周年纪念币，过程比较坎坷，不过最终还是兑换成功了。 预约 ? 纪念币成功后，今天中秋假期，正好去兑换纪念币，小雨转中雨 ☁️，作为多年没有使用纸质人民币的我实在是没有钱来兑换纪念币，之后搜索了一下附近可以兑换人民币的营业厅，都在千米之外，算了…… 突然想到前两天美团有一个数字人民币的活动，下载了数字人民币 APP，研究了一下，发现有工商银行支持数字人民币，之后搜寻了一下网点，发现北京地区都是支持数字人民币的了，之后我就去申请了工商银行电子钱包，往里面转了 200 元钱，之后去银行网点ing。 到了之后工作人员引领到专门兑换纪念币柜台，我问了一下是否可以使用数字人民币兑换，好家伙，社死瞬间，一下来了 6 个工作人员看我操作，柜台小姐姐说没有操作过数字人民币付款，之后那我当一下小白鼠 ? ？ 操作出来数字人民币支付二维码页面，之后扫描发现不能使用 emmmmm，尴尬，看了提示，原来是让我下载工行的 APP，之后使用上面的数字人民币进行支付，一通下载注册之后，再次去柜台兑换，扫码 =\u003e 支付，等了 5s 左右，最终成功兑换了纪念币，现在想想，我应该是第一个使用数字人民币兑换纪念币的第一人了吧。 数字人民币未来由国家导向大力推广，会使人民的支付更加便捷，不过个人建议纸质币保留下来，照顾不会使用手机的老年群体，总之，技术的进步，未来看来我们都是为了一串数字而奋斗喽。 ","date":"2021-09-19","objectID":"/coin-use-epay/:0:0","tags":["coin","e-pay","数字人民币","纪念币"],"title":"使用数字人民币兑换建党100周年纪念币","uri":"/coin-use-epay/"},{"categories":["golang"],"content":"译文原地址：Should methods be declared on T or *T - David 在 Go 中，对于任何的类型 T，都存在一个类型 *T，他是一个表达式的结果，该表达式接收的是类型 T ，例如： type T struct { a int; b bool } var t T // t's type is T var p = \u0026t // p's type is *T 这两种类型，T 和 *T 是不同的，但 *T 不能代替 T。 你可以在你拥有的任意类型上声明一个方法；也就是说，在您的包中的函数声明的类型。因此，您可以在声明的类型 T 和对应的派生指针类型 *T 上声明方法。另一种说法是，类型上的方法被声明为接收器接收者值的副本，或一个指向其接收者值的指针。所以问题就存在了，究竟是哪种形式最合适？ 显然，如果你的方法改变了他的接收者，他应该在 *T 上声明。但是，如果方法不改变他的接收者，在 T 上声明它是安全的么？ 事实证明，这样做的话安全的情况非常有限（简单理解就是不安全的）。例如，众所周知，你不应该复制一个 sync.Mutex 的值，因为它打破了互斥量的不变量。由于互斥锁控制对变量（共享资源）的访问，他们经常被包装在一个结构体中，包含他们的控制的值（共享资源）： package counter type Val struct { mu sync.Mutex val int } func (v *Val) Get() int { v.mu.Lock() defer v.mu.Unlock() return v.val } func (v *Val) Add(n int) { v.mu.Lock() defer v.mu.Unlock() v.val += n } 大部分 Gopher 都知道，忘记在指针接收器 *Val 上是声明 Get 或 Add 方法是错误的。然而，任何嵌入 Val 来利用其 0 值的类型，也必须仅在其指针接收器上声明方法，否者可能会无意复制其嵌入类型值的内容： type Stats struct { a, b, c counter.Val } func (s Stats) Sum() int { return s.a.Get() + s.b.Get() + s.c.Get() // whoops（哎呀） } 维护值切片的类型可能会出现类似的陷阱，当然也有可能发生意外的数据竞争。 简而言之，我认为您更应该喜欢在 *T 上声明方法，除非您有非常充分的理由不该这样做。 我们说 T 但这只是您声明的类型的占位符； 此规则是递归的，取 *T 类型的变量的地址返回的是 **T 类型的结果； 这就是为什么没有人可以在像 int 这样的基础类型上声明方法； Go 中的方法只是将接受者作为第一个形式参数传递的函数的语法糖； 如果方法不改变它的接收者，它是否需要是一个方法吗？ 相关文章： What is the zero value, and why is it useful? Ice cream makers and data races Slices from the ground up The empty struct 最后，此篇文章我是第一次尝试翻译英文文章，尽管英文水平不太好，一些单词不认识，但是相信自己翻译一篇文章可以学习英语与理解 Go 设计获取 double 的乐趣。 ","date":"2021-06-27","objectID":"/go-metheds-on-t/:0:0","tags":["go","translate"],"title":"[译] 方法是否应该在 T 或 *T 上声明","uri":"/go-metheds-on-t/"},{"categories":["summary"],"content":"距离最后一篇博文 《Go 语言开发设计指北》发布已经过去一个多月的时间了，在这一段的时间里，在看了大量的书籍?，在工作上安排的工作都比较得心应手，时间还算比较充裕，但是懒惰心里没有丝毫退去 ?，这样是不行的，很容易让自己的思维和学习能力下降。 先来谈谈近期阅读的一些文章吧，《高性能 MySQL》这一本书相信是计算机从业人员必读的一本书 ? 了吧，这本书虽然看起来比较厚，但是里面的知识面和富有情趣的讲解还是很不错的，给作者点个赞，现在是第一遍读这本书，本着：“先把书读薄”的原则来读，已经攻读了3章多了，学到了很多实际中业务开发的宝贵经验，但是在实际设计中还是会落入坑中，学到了主键、索引设计技巧，以及具体是怎么去使用的，自己所书写的每一条 SQL 语句是在 MySQL中是怎样运行的，执行效率如何，是否可以优化，以及怎么去衡量自己优化的效率可以达到多少，在这本书中都有所讲解。 第二本就是在极客时间上追更鸟窝大神的《Go语言并发实战》，学习了学多的Go语言并发设计所使用到的并发原语及处理方法，包括 Mutex、RWMutex、WaitGroup、Pool、Once、Context等等操作及内部实现，emmm 目前看老师已经更新完了 自己还没有追更完，惭愧呀，Flag 要树立起来了，哈哈。 第三本是《GC的认识》，在开发过程中，自己在业务代码的设计中无需考虑变量声明后销毁的流程，因为在Go语言中已经实现了对堆栈资源的销毁与清理，但是GC是怎么操作的自己之前都是模糊的了解有三色标记，从根出发标记，很笼统的概念，近期看的这本书，严格意义上一笔记，就讲解了GC的执行过程，怎么去观察GC操作以及怎么去对GC优化等操作，详细的就不展开了，大家感兴趣的可以去看一下。 还有就是一些小的细节点的学习了，还有对自己项目组中的项目及框架了解了一下，这里就不分享啦，实际上是不知道是否存在蟹蜜危机。 毕竟上一篇文章发布的时候就战战兢兢 。 结尾呼应标题，这是一篇水文，主要是想告诉大家 Meng小羽并没有跑路 Debug客栈 还在，另外希望大家有好的分享资料的分享的话可以和我互动或者加入我的群聊，毕竟 1+1 \u003e 2 的，对吧。好了不多说了，跑步去了 ?。 ","date":"2021-04-24","objectID":"/debuginn-2021-emmm/:0:0","tags":["碎碎念"],"title":"emmm 这是一篇碎碎念","uri":"/debuginn-2021-emmm/"},{"categories":["golang"],"content":"Go 语言是一种强类型、编译型的语言，在开发过程中，代码规范是尤为重要的，一个小小的失误可能会带来严重的事故，拥有一个良好的 Go 语言开发习惯是尤为重要的，遵守开发规范便于维护、便于阅读理解和增加系统的健壮性。 以下是我们项目组开发规范加上自己开发遇到的问题及补充，希望对你有所帮助： 注：我们将以下约束分为三个等级，分别是：【强制】、【推荐】、【参考】。 ","date":"2021-03-07","objectID":"/go-dev-design/:0:0","tags":["go","mysql","redis","code review","log","stat","go fmt"],"title":"Go 语言开发设计指北","uri":"/go-dev-design/"},{"categories":["golang"],"content":"Go 编码相关 【强制】代码风格规范遵循 go 官方标准：CodeReviewComments，请使用官方 golint lint 进行风格静态分析； 【强制】代码格式规范依照 gofmt，请安装相关 IDE 插件，在保存代码或者编译时，自动将源码通过 gofmt 做格式化处理，保证团队代码格式一致（比如空格，递进等） 【强制】业务处理代码中不能开 goroutine，此举会导致 goroutine 数量不可控，容易引起系统雪崩，如果需要启用 goroutine 做异步处理，请在初始化时启用固定数量 goroutine，通过 channel 和业务处理代码交互，初始化 goroutine 的函数，原则上应该从 main 函数入口处明确的调用： func crond() { defer func() { if err := recover(); err != nil { // dump stack \u0026 log } }() // do something } func main() { // init system go crond() go crond2() // handlers } 【强制】异步开启 goroutine 的地方（如各种 cronder )，需要在最顶层增加 recover()，捕捉 panic，避免个别 cronder 出错导致整体退出： func globalCrond() { for _ := ticker.C { projectCrond() itemCrond() userCrond() } } func projectCrond() { defer func() { if err := recover(); err != nil { // 打日志，并预警 } } // do } 【强制】当有并发读写 map 的操作，必须加上读写锁 RWMutex，否则 go runtime 会因为并发读写报 panic，或者使用 sync.Map 替代； 【强制】对于提供给外部使用的 package，返回函数里必须带上 err 返回，并且保证在 err == nil 情况下，返回结果不为 nil，比如： resp, err := package1.GetUserInfo(xxxxx) // 在err == nil 情况下，resp不能为nil或者空值 【强制】当操作有多个层级的结构体时，基于防御性编程的原则，需要对每个层级做空指针或者空数据判别，特别是在处理复杂的页面结构时，如： type Section struct { Item *SectionItem Height int64 Width int64 } type SectionItem struct { Tag string Icon string ImageURL string ImageList []string Action *SectionAction } type SectionAction struct { Type string Path string Extra string } func getSectionActionPath(section *Section) (path string, img string, err error) { if section.Item == nil || section.Item.Action == nil { // 要做好足够防御，避免因为空指针导致的panic err = fmt.Errorf(\"section item is invalid\") return } path = section.Item.Action.Path img = section.Item.ImageURL // 对取数组的内容，也一定加上防御性判断 if len(section.Item.ImageList) \u003e 0 { img = section.Item.ImageList[0] } return } 【推荐】生命期在函数内的资源对象，如果函数逻辑较为复杂，建议使用 defer 进行回收： func MakeProject() { conn := pool.Get() defer pool.Put(conn) // 业务逻辑 ... return } 对于生命期在函数内的对象，定义在函数内，将使用栈空间，减少 gc 压力： func MakeProject() (project *Project){ project := \u0026Project{} // 使用堆空间 var tempProject Project // 使用栈空间 return } 【强制】不能在循环里加 defer，特别是 defer 执行回收资源操作时。因为 defer 是函数结束时才能执行，并非循环结束时执行，某些情况下会导致资源（如连接资源）被大量占用而程序异常： // 反例： for { row, err := db.Query(\"SELECT ...\") if err != nil { ... } defer row.Close() // 这个操作会导致循环里积攒许多临时资源无法释放 ... } // 正确的处理，可以在循环结束时直接close资源，如果处理逻辑较复杂，可以打包成函数： for { func () { row, err := db.Query(\"SELECT ...\") if err != nil { ... } defer row.Close() ... }() } 【推荐】对于可预见容量的 slice 或者 map，在 make 初始化时，指定cap大小，可以大大降低内存损耗，如： headList := make([]home.Sections, 0, len(srcHomeSection)/2) tailList := make([]home.Sections, 0, len(srcHomeSection)/2) dstHomeSection = make([]*home.Sections, 0, len(srcHomeSection)) …. if appendToHead { headList = append(headList, info) } else { tailList = append(tailList, info) } …. dstHomeSection = append(dstHomeSection, headList…) dstHomeSection = append(dstHomeSection, tailList…) 【推荐】逻辑操作中涉及到频繁拼接字符串的代码，请使用 bytes.Buffer 替代。使用 string 进行拼接会导致每次拼接都新增 string 对象，增加 GC 负担： // 正例： var buf bytes.Buffer for _, name := range userList { buf.WriteString(name) buf.WriteString(\",\") } return buf.String() // 反例： var result string for _, name := range userList { result += name + \",\" } return result 【强制】对于固定的正则表达式，可以在全局变量初始化时完成预编译，可以有效加快匹配速度，不需要在每次函数请求中预编译： var wordReg = regexp.MustCompile(\"[\\\\w]+\") func matchWord(word string) bool { return wordReg.MatchString(word) } 【推荐】JSON 解析时，遇到不确定是什么结构的字段，建议使用 json.RawMessage 而不要用 interface，这样可以根据业务场景，做二次 unmarshal 而且性能比 interface 快很多； 【强制】锁使用的粒度需要根据实际情况进行把控，如果变量只读，则无需加锁；读写，则使用读写锁 sync.RWMutex； 【强制】使用随机数时(math/rand)，必须要做随机初始化(rand.Seed)，否则产生出的随机数是可预期的，在某些场合下会带来安全问题。一般情况下，使用math/rand可以满足业务需求，如果开发的是安全模块，建议使用crypto/rand，安全性更好； 【推荐】对性能要求很高的服务，或者对程序响应时间要求高的服务，应该避免开启大量 gouroutine； 说明：官方虽然号称 goroutine 是廉价的，可以大量开启 goroutine，但是由于 goroutine 的调度并没有实现优先级控制，使得一些关键性的 goroutine（如网络/磁盘IO，控制全局资源的goroutine）没有及时得到调度而拖慢了整体服务的响应时间，因而在系统设计时，如果对性能要求很高，应避免开启大量goroutine。 ","date":"2021-03-07","objectID":"/go-dev-design/:1:0","tags":["go","mysql","redis","code review","log","stat","go fmt"],"title":"Go 语言开发设计指北","uri":"/go-dev-design/"},{"categories":["golang"],"content":"打点规范 【强制】打点使用.来做分隔符，打点名称需要包含业务名，模块，函数，函数处理分支等，参考如下： // 业务名.服务名.模块.功能.方法 service.gateway.module.action.func 【强制】打点使用场景是监控系统的实时状态，不适合存储任何业务数据； 【强制】在打点个数太多时，展示时速度会变慢。建议单个服务打点的key不超过10000个，key中单个维度不同值不超过 1000个（千万不要用 user_id 来打点)； 【推荐】如果展示的时候需要拿成百上千个key的数据通过 Graphite 的聚合函数做聚合，最后得到一个或几个 key。这种情况下可以在打点的时候就把这个要聚合的点聚合好，这样展示的时候只要拿这几个 key，对展示速度是巨大的提升。 ","date":"2021-03-07","objectID":"/go-dev-design/:2:0","tags":["go","mysql","redis","code review","log","stat","go fmt"],"title":"Go 语言开发设计指北","uri":"/go-dev-design/"},{"categories":["golang"],"content":"日志相关 【强制】日志信息需带上下文，其中 logid 必须带上，同一个请求打的日志都需带上 logid，这样可以根据 logid 查找该次请求相关的信息； 【强制】对debug/notice/info 级别的日志输出，必须使用条件输出或者使用占位符方式，避免使用字符拼接方式： log.Debug(\"get home page failed %s, id %d\", err, id) 【强制】如果是解析 json 出错的日志，需要将报错 err 及原内容一并输出，以方便核查原因； 【推荐】对debug/notice/info级别的日志，在打印日志时，默认不显示调用位置（如/path/to/code.go:335） 说明：go 获取调用栈信息是比较耗时的操作(runtime.Caller)，对于性能要求很高的服务，特别是大量调用的地方，应尽量避免开发人员在使用该功能时，需知悉这个调用带来的代价。 ","date":"2021-03-07","objectID":"/go-dev-design/:3:0","tags":["go","mysql","redis","code review","log","stat","go fmt"],"title":"Go 语言开发设计指北","uri":"/go-dev-design/"},{"categories":["golang"],"content":"Redis 相关 【推荐】统一使用:作为前缀后缀分隔符，这里可以根据 Redis 中间件 key proxy 怎么解析分析 Key 进行自定义，便于基础服务的数据可视化及问题排查； 【强制】避免使用 HMGET/HGETALL/HVALS/HKEYS/SMEMBERS 阻塞命令这类命令在 value 较大时，对 Redis 的 CPU/带宽消耗较高，容易导致响应过慢引发系统雪崩； 【强制】不可把 Redis 当成存储，如有统计相关的需求，可以考虑异步同步到数据库进行统计，Redis 应该回归缓存的本质； 【推荐】避免使用大 key，按经验超过 10k 的 value，可以压缩(gzip/snappy等算法)后存入内存，可以减少内存使用，其次降低网络消耗，提高响应速度： value, err := c.RedisCache.GetGzip(key) …. c.RedisCache.SetExGzip(content, 60) 【推荐】Redis 的分布式锁，可以使用: lock: redis.Do(\"SET\", lockKey, randint, \"EX\", expire, \"NX\") unlock: redis.GetAndDel(lockKey, randint) // redis暂不支持，可以用lua脚本 【推荐】尽量避免在逻辑循环代码中调用 Redis，会产生流量放大效应，请求量较大时需采用其他方法优化（比如静态配置文件）； 【推荐】key 尽量离散读写，通过uid/imei/xid等跟用户/请求相关的后缀分摊到不同分片，避免分片负载不均衡； 【参考】当缓存量大，请求量较高，可能超出 Redis 承受范围时，可充分利用本地缓存(localcache)+redis缓存的组合方案来缓解压力，削减峰值： 使用这个方法需要具备这几个条件： cache 内容与用户无关，key 状态不多，属于公共信息； 该cache内容时效性较高，但是访问量较大，有峰值流量。 key := \"demoid:3344\" value := localcacche.Get(key) if value == \"\" { value = rediscache.Get(key) if value != \"\" { // 随机缓存 1~5s，各个机器间错开峰值，只要比 redis缓存短即可 localcache.SetEx(key, value, rand.Int63n(5)+1) } } if value == \"\" { .... // 从其他系统或者数据库获取数据 appoint.GetValue() // 同时设置到redis及localcache中 rediscache.SetEx(key, content, 60) localcache.SetEx(key, content, rand.Int63n(5)+1) } 【参考】对于请求量高，实时性也高的内容，如果纯粹使用缓存，当缓存失效瞬间，会导致大量请求穿透到后端服务，导致后端服务有雪崩危险： 如何兼顾扛峰值，保护后端系统，同时也能保持实时性呢？在这种场景下，可以采用随机更新法更新数据，方法如下： 正常请求从缓存中读取，缓存失效则从后端服务获取； 在请求中根据随机概率 1%（或者根据实际业务场景设置比率）会跳过读取缓存操作，直接从后端服务获取数据，并更新缓存。 这种做法能保证最低时效性，并且当访问量越大，更新概率越高，使得内容实时性也越高。 如果结合上一条 localcache+rediscache 做一二级缓存，则可以达到扛峰值同时保持实时性。 ","date":"2021-03-07","objectID":"/go-dev-design/:4:0","tags":["go","mysql","redis","code review","log","stat","go fmt"],"title":"Go 语言开发设计指北","uri":"/go-dev-design/"},{"categories":["golang"],"content":"数据库相关 【强制】操作数据库 sql 必须使用 stmt 格式，使用占位符替代参数，禁止拼接 sql； 【强制】SQL语句查询时，不得使用 SELECT * （即形如 SELECT * FROM tbl WHERE），必须明确的给出要查询的列名，避免表新增字段后报错； 【强制】对于线上业务 SQL，需保证命中索引，索引设计基于业务需求及字段区分度，一般可区分状态不高的字段（如 status 等只有几个状态），不建议加到索引中； 【强制】在成熟的语言中，有实体类，数据访问层(repository / dao)和业务逻辑层( service )；在我们的规范中存储实体 struct 放置于 entities 包下； 【强制】对于联合索引，需将区分度较大的字段放前面，区分度小放后面，查找时可以减少被检索数据量； -- 字段区分度 item_id \u003e project_id alter table xxx add index idx_item_project ( item_id , project_id ) 【强制】所有数据库表必须有主键 id； 【强制】主键索引名为 pk字段名; 唯一索引名为 uk字段名; 普通索引名则为 idx_字段名； 【强制】防止因字段类型不同造成的隐式转换，导致索引失效，造成全表扫描问题； 【强制】业务上有唯一特性的字段，即使是多字段的组合，也必须建成唯一索引； 【强制】一般事务标准操作流程： func TestTXExample(t *testing.T) { // 打开事务 tx, err := db.Beginx() if err != nil { log.Fatal(\"%v\", err) return } // defer异常 needRollback := true defer func() { if r := recover(); r != nil { // 处理recover，避免因为panic，资源无法释放 log.Fatal(\"%v\", r) needRollback = true } if needRollback { xlog.Cause(\"test.example.transaction.rollback\").Fatal() tx.Rollback() } }() // 事务的逻辑 err = InsertLog(tx, GenTestData(1)[0]) if err != nil { log.Fatal(\"%v\", err) return } // 提交事务 err = tx.Commit() if err != nil { log.Fatal(\"%v\", err) return } needRollback = false return } 【强制】执行事务操作时，请确保SELECT ... FOR UPDATE条件命中索引，使用行锁，避免一个事务锁全表的情况; 【强制】禁止超过三个表的 join，需要 join 的字段，数据类型必须一致，多表关联查询时，保证被关联的字段有索引; 【强制】数据库 max_open 连接数不可设置过高，会导致代理连接数打满导致不可用状况; ","date":"2021-03-07","objectID":"/go-dev-design/:5:0","tags":["go","mysql","redis","code review","log","stat","go fmt"],"title":"Go 语言开发设计指北","uri":"/go-dev-design/"},{"categories":["summary"],"content":"2021 年的一月份马上就过去了，在这一个月中，并没有新鲜出炉的博文，恰恰相反的是我这一个月以来，在思考，自己的博客怎么输出高质量有水平的文章，正如一首优美的旋律，怎么听都可以让人回味无穷，每一遍都有自己的收获。 关于提升自己博客文章的水平，这个月思考了很多的方向，也阅读了不少人对于博客的看法和理解，最终对自己博客总结了几点不足之处： 看到及听到一种新技术或者新的事物，总是以为看了几篇的相关的文章介绍及简短的理解文章，就认为自己了解了某一个事物或者技术，之后输出自己的想法，写出一篇总结的文章，理所应当的写不出有深度有营养的文章； 写一篇博文访问量的关注与文章输出的内容对比更倾向于前者，突然感觉到自己很肤浅，本末倒置，好的文章输出最不用关心的就是访问量的问题； 博文不是自己的 OKR，而是自己技术的自留地，入职大厂之后，感觉自己的技术文章输出应该高出一个层次，一些浅显易懂的或者容易学到的点就不需要总结成文章了，眼高手低，没有认清自己的技术与输出的水平； 自己的技术储备不足（看的书及教程少），博客中一些文章还停留在了解的层次，并没有真正的去 Get 到每个的深层次的水平中去； 懒惰的心理，短视频及游戏 ? VS Debug客栈，大部分时间选择前者，但是前者看了再多，玩的再6，也提升不了自己，只能当算法喂养下的白痴。 毫不夸张的说，若是把博客水平比做成人的一生，我的博客水平依旧处在了18岁之前，没有自己的思考，更多的是在教程、分享的模版下输出，虽有输出，但今天的我发现并没有太多的营养。 正如上方的分割线，我希望自己未来的输出在这里是一个分水岭，接下来自己可以学到更多，变得更强，让自己输出的文章有深度，自己的编程技术更加有水平。 回归主题，“如何提升自己的技术博文水平”，其实映射出是自己的技术水平的不足导致的，那如何提升自己的技术水平，自己总结了一下接下来要做的努力： 阅读技术书籍，技术不能停留在会使用的阶段，要知道自己的每一步操作，在计算机内部发生了什么，原理及使用的技术是什么，现在的我谈不上如何去改进某个技术，但是要会灵活的使用现有技术提升自己的编程水平，提高自己代码的稳定性及让自己的代码写出来如诗一般优雅； 在本职工作中，多看项目组及同事的代码，不仅仅是看代码，思考为什么这样设计，这样设计带来的好处是什么，会有哪些不足，如何改进及优化； 在流行的技术及 Go 语言包中，加入到开源的项目中去，多去看大佬们的代码及设计哲学，了解业界技术的更迭及主流用法，可以的话贡献自己的代码； 多去交流技术，不能认为自己代码很 Low，没有了解很多就对研讨会或者分享会望而却步，恰恰相反，自己在这些分享会中会发现自己的水平处在什么阶段及自己如何去提升自己； 多去整理学过了、了解到的技术的笔记，学会提炼及吸收成自己的知识体系： 这是自己搭建的笔记平台：https://notes.debuginn.cn 自己的学习笔记都会同步至此平台，更多的是自己的学习笔记及重要的知识点，这就是我的小本本。 最后，感谢自己导师的教诲与提醒，自己要更加的努力，提升自己，2021，定不负大家的厚望，努力成为项目组中的中坚力量，加油！！！撰写出更多有营养的文章，当然，有些理解片面或者不足的文章还请大家批评指出，谢谢 ","date":"2021-01-30","objectID":"/debuginn-write-blog/:0:0","tags":["技术","博文"],"title":"如何提升自己的技术博文水平","uri":"/debuginn-write-blog/"},{"categories":["summary"],"content":"今年，最大的感受就是时间过的太快了，一切都是那么的来不及 …… 2020 年，疫情、毕业、工作，学生时代的 END，社会人时代的 START …… 2021 年，希望一切都在慢慢变好，新的开始、新的未来！！！ 每一次总结都是新的开始的起点，那么，接下来就开始吧～ ","date":"2020-12-31","objectID":"/debuginn-2020/:0:0","tags":["Debug客栈","2020","2021","年度总结"],"title":"2020 年度总结","uri":"/debuginn-2020/"},{"categories":["summary"],"content":"网站数据 今年是小站运行的第 4 年，感谢大家的支持与访问，这是我分享的天地、同时也是见证我成长的地方，加油～ 一往无前 ！！！ ","date":"2020-12-31","objectID":"/debuginn-2020/:1:0","tags":["Debug客栈","2020","2021","年度总结"],"title":"2020 年度总结","uri":"/debuginn-2020/"},{"categories":["summary"],"content":"最受欢迎的文章 Restful API 设计指北 https://www.debuginn.cn/5178.html 吊打百度，多吉搜索引擎 程序猿的 Chrome 浏览器插件推荐 搭建流媒体服务器 PingOS 平台搭建 怎么优雅的选择 MySQL 存储引擎 ","date":"2020-12-31","objectID":"/debuginn-2020/:2:0","tags":["Debug客栈","2020","2021","年度总结"],"title":"2020 年度总结","uri":"/debuginn-2020/"},{"categories":["summary"],"content":"More 页面 2020 看见的我不止一面，这里记录了我的 MORE https://www.debuginn.cn/more ","date":"2020-12-31","objectID":"/debuginn-2020/:3:0","tags":["Debug客栈","2020","2021","年度总结"],"title":"2020 年度总结","uri":"/debuginn-2020/"},{"categories":["golang"],"content":"Mutex 是用来保证只有一个 goroutine 访问共享资源，在大量的并发场景中，特别是读场景中，一个共享资源块只能让 goroutine 串行访问，这就导致了性能的影响，解决方法就是区分读写操作。 这样就可以将串行的读变成并行的读，用来提高读操作的性能。 Go 标准库 RWMutex （读写锁）就是用来解决 readers-writers 问题的。 ","date":"2020-12-05","objectID":"/go-concurrence-rw-mutex/:0:0","tags":["go","concurrence","RWMutex"],"title":"Go 并发编程之 RWMutex","uri":"/go-concurrence-rw-mutex/"},{"categories":["golang"],"content":"RWMutex 标准库中的 RWMutex 是一个 reader/writer 互斥锁，RWMutex 在同一时间只能由 n 个 reader 持有，或者只能被单个的 writer 持有。 Lock/Unlock：写操作时调用的方法，若是被 reader 或者 writer 持有， Lock 会一直阻塞，直到可以获取到锁，Ulock 是释放锁； Rlock/RUnlock：读操作时低哦用的方法，如果已经被 writer 持有的话， Rlock 会一直阻塞，直到获取到锁，否者直接返回， RUlock 是 reader 释放锁的方法； RLocker：为读操作返回一个 Locker 接口的对象。 RWMutex 的零值是未加锁的状态，所以在使用 RWMutex 作为变量或者嵌入到 struct 中去，都没有必要进行显式的初始化。 ","date":"2020-12-05","objectID":"/go-concurrence-rw-mutex/:1:0","tags":["go","concurrence","RWMutex"],"title":"Go 并发编程之 RWMutex","uri":"/go-concurrence-rw-mutex/"},{"categories":["golang"],"content":"实现原理 针对于 readers-writers 问题是基于对读和写操作的优先级，读写锁的设计分为三类： Read-preferring 读优先设计：并发效果好，但是在大量的并发场景下会导致写饥饿； Write-preferring 写优先设计：针对新请求而言，主要是避免了 writer 饥饿问题，也就是说同一时间有一个 reader 和 writer 等待获取锁，会优先给 writer； 不指定优先级：FIFO，不区分读写优先级，适用于某些特定的场景。 RWMutex 设计是 write-preferring 写优先设计。一个正在阻塞的 Lock 调用会排出新的 reader 请求到锁。 RWMutex 包含一个 Mutex，以及四个辅助字段 writerSem、readerSem、readerCount 和 readerWait： type RWMutex struct { w Mutex // 互斥锁解决多个 writer 的竞争 writerSem uint32 // writer 信号量 readerSem uint32 // reader 信号量 readerCount int32 // reader 的数量，记录当前 reader 等待的数量 readerWait int32 // writer 等待完成的 reader的 数量 } const rwmutexMaxReaders = 1 \u003c\u003c 30 ","date":"2020-12-05","objectID":"/go-concurrence-rw-mutex/:2:0","tags":["go","concurrence","RWMutex"],"title":"Go 并发编程之 RWMutex","uri":"/go-concurrence-rw-mutex/"},{"categories":["golang"],"content":"RLock/RUlock 实现 func (rw *RWMutex) RLock() { // 对 reader 计数 +1，readerCount 会出现负数 // 1、没有 writer 竞争或者持有锁的时候，readerCount 充当计数器存在 // 2、如果有 writer 竞争锁或者持有锁时，那么，readerCount 不仅仅承担着 reader 的计数功能，还能够标识当前是否有 writer 竞争或持有锁 if atomic.AddInt32(\u0026rw.readerCount, 1) \u003c 0 { // rw.readerCount 是负值的时候，意味着此时有 writer 等待请求锁 // 因为writer优先级高，所以把后来的 reader 阻塞休眠 runtime_SemacquireMutex(\u0026rw.readerSem, false, 0) } } func (rw *RWMutex) RUnlock() { // 将 reader 计数 -1 if r := atomic.AddInt32(\u0026rw.readerCount, -1); r \u003c 0 { // 如果为 负数，代表着当前有 writer 在竞争锁，检查是不是所有的 reader 都将锁释放 // 若释放了就让 writer 获取到锁进行写操作 rw.rUnlockSlow(r) // 有等待的writer } } func (rw *RWMutex) rUnlockSlow(r int32) { // rUnlockSlow 将持有锁的 reader 计数 -1 的时候； // 会检查既有的 reader 是不是都已经释放了锁； // 如果都释放了锁，就会唤醒 writer，让 writer 持有锁。 if atomic.AddInt32(\u0026rw.readerWait, -1) == 0 { // 最后一个reader了，writer终于有机会获得锁了 runtime_Semrelease(\u0026rw.writerSem, false, 1) } } ","date":"2020-12-05","objectID":"/go-concurrence-rw-mutex/:2:1","tags":["go","concurrence","RWMutex"],"title":"Go 并发编程之 RWMutex","uri":"/go-concurrence-rw-mutex/"},{"categories":["golang"],"content":"Lock / Unlock RWMutex 是一个多 writer 多 reader 的读写锁，所以同时可能有多个 writer 和 reader。那么，为了避免 writer 之间的竞争，RWMutex 就会使用一个 Mutex 来保证 writer 的互斥。 func (rw *RWMutex) Lock() { // 首先解决其他 writer 竞争问题 rw.w.Lock() // 反转 readerCount，告诉 reader 有 writer 竞争锁 r := atomic.AddInt32(\u0026rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // 如果当前有 reader 持有锁，那么需要等待 if r != 0 \u0026\u0026 atomic.AddInt32(\u0026rw.readerWait, r) != 0 { runtime_SemacquireMutex(\u0026rw.writerSem, false, 0) } } 一旦一个 writer 获得了内部的互斥锁，就会反转 readerCount 字段，把它从原来的正整数 readerCount(\u003e=0) 修改为负数（readerCount-rwmutexMaxReaders），让这个字段保持两个含义（既保存了 reader 的数量，又表示当前有 writer）。 func (rw *RWMutex) Unlock() { // 告诉 reader 没有活跃的 writer 了 r := atomic.AddInt32(\u0026rw.readerCount, rwmutexMaxReaders) // 唤醒阻塞的 reader 们 for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // 释放内部的互斥锁 rw.w.Unlock() } 当一个 writer 释放锁的时候，它会再次反转 readerCount 字段。可以肯定的是，因为当前锁由 writer 持有，所以，readerCount 字段是反转过的，并且减去了 rwmutexMaxReaders 这个常数，变成了负数。 所以，这里的反转方法就是给它增加 rwmutexMaxReaders 这个常数值。既然 writer 要释放锁了，那么就需要唤醒之后新来的 reader，不必再阻塞它们了，让它们开开心心地继续执行就好了。 在 RWMutex 的 Unlock 返回之前，需要把内部的互斥锁释放。释放完毕后，其他的 writer 才可以继续竞争这把锁。 ","date":"2020-12-05","objectID":"/go-concurrence-rw-mutex/:2:2","tags":["go","concurrence","RWMutex"],"title":"Go 并发编程之 RWMutex","uri":"/go-concurrence-rw-mutex/"},{"categories":["golang"],"content":"RWMutex 常犯的三种错误 不可复制 重入导致死锁 释放未加锁的 RWMutex ","date":"2020-12-05","objectID":"/go-concurrence-rw-mutex/:2:3","tags":["go","concurrence","RWMutex"],"title":"Go 并发编程之 RWMutex","uri":"/go-concurrence-rw-mutex/"},{"categories":["golang"],"content":"我们比较常见的大型项目的设计中都会出现并发访问问题，并发就是为了解决数据的准确性，保证同一个临界区的数据只能被一个线程进行操作，日常中使用到的并发场景也是很多的： 计数器：计数器结果不准确； 秒杀系统：由于同一时间访问量比较大，导致的超卖； 用户账户异常：同一时间支付导致的账户透支； buffer 数据异常：更新 buffer 导致的数据混乱。 上面都是并发带来的数据准确性的问题，决绝方案就是使用互斥锁，也就是今天并发编程中的所要描述的 Mutex 并发原语。 ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:0:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"实现机制 互斥锁 Mutex 就是为了避免并发竞争建立的并发控制机制，其中有个“临界区”的概念。 在并发编程过程中，如果程序中一部分资源或者变量会被并发访问或者修改，为了避免并发访问导致数据的不准确，这部分程序需要率先被保护起来，之后操作，操作结束后去除保护，这部分被保护的程序就叫做临界区。 使用互斥锁，限定临界区只能同时由一个线程持有，若是临界区此时被一个线程持有，那么其他线程想进入到这个临界区的时候，就会失败或者等待释放锁，持有此临界区的线程退出，其他线程才有机会获得这个临界区。 Mutex 是 Go 语言中使用最广泛的同步原语，也称为并发原语，解决的是并发读写共享资源，避免出现数据竞争 data race 问题。 ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:1:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"基本使用 互斥锁 Mutex 提供了两个方法 Lock 和 Unlock：进入到临界区使用 Lock 方法加锁，退出临界区使用 Unlock 方法释放锁。 type Locker interface { Lock() Unlock() } func(m *Mutex)Lock() func(m *Mutex)Unlock() 当一个 goroutine 调用 Lock 方法获取到锁后，其他 goroutine 会阻塞在 Lock 的调用上，直到当前获取到锁的 goroutine 释放锁。 接下来是一个计数器的例子，是由 100 个 goroutine 对计数器进行累加操作，最后输出结果： package main import ( \"fmt\" \"sync\" ) func main() { var mu sync.Mutex countNum := 0 // 确认辅助变量是否都执行完成 var wg sync.WaitGroup // wg 添加数目要和 创建的协程数量保持一致 wg.Add(100) for i := 0; i \u003c 100; i++ { go func() { defer wg.Done() for j := 0; j \u003c 1000; j++ { mu.Lock() countNum++ mu.Unlock() } }() } wg.Wait() fmt.Printf(\"countNum: %d\", countNum) } ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:2:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"实际使用 很多时候 Mutex 并不是单独使用的，而是嵌套在 Struct 中使用，作为结构体的一部分，如果嵌入的 struct 有多个字段，我们一般会把 Mutex 放在要控制的字段上面，然后使用空格把字段分隔开来。 甚至可以把获取锁、释放锁、计数加一的逻辑封装成一个方法。 package main import ( \"fmt\" \"sync\" ) // 线程安全的计数器 type Counter struct { CounterType int Name string mu sync.Mutex count uint64 } // 加一方法 func (c *Counter) Incr() { c.mu.Lock() defer c.mu.Unlock() c.count++ } // 取数值方法 线程也需要受保护 func (c *Counter) Count() uint64 { c.mu.Lock() defer c.mu.Unlock() return c.count } func main() { // 定义一个计数器 var counter Counter var wg sync.WaitGroup wg.Add(100) for i := 0; i \u003c 100; i++ { go func() { defer wg.Done() for j := 0; j \u003c 1000; j++ { counter.Incr() } }() } wg.Wait() fmt.Printf(\"%d\\n\", counter.Count()) } ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:3:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"思考问题 Q：你已经知道，如果 Mutex 已经被一个 goroutine 获取了锁，其它等待中的 goroutine 们只能一直等待。那么，等这个锁释放后，等待中的 goroutine 中哪一个会优先获取 Mutex 呢？ A：FIFO，先来先服务的策略，Go 的 goroutine 调度中，会维护一个保障 goroutine 运行的队列，当获取到锁的 goroutine 执行完临界区的操作的时候，就会释放锁，在队列中排在第一位置的 goroutine 会拿到锁进行临界区的操作。 ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:4:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"实现原理 Mutex 的架构演进目前分为四个阶段： 初版 Mutex：使用一个 flag 变量表示锁?是否被持有； 给新人机会：照顾新来的 goroutine 先获取到锁； 多给些机会：照顾新来的和被唤醒的 goroutine 获取到锁； 解决饥饿：存在竞争关系，有饥饿情况发生，需要解决。 ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:5:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"初版 Mutex // 互斥锁的结构，包含两个字段 type Mutex struct { key int32 // 锁是否被持有的标识 sema int32 // 信号量专用，用以阻塞/唤醒goroutine } Unlock 方法可以被任意的 goroutine 调用释放锁，即使是没持有这个互斥锁的 goroutine，也可以进行这个操作。这是因为，Mutex 本身并没有包含持有这把锁的 goroutine 的信息，所以，Unlock 也不会对此进行检查。Mutex 的这个设计一直保持至今。 在使用 Mutex 的时候，需要严格遵循 “谁申请，谁释放” 原则。 ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:5:1","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"解决饥饿 由于使用了给新人机会，又肯呢个会出现每次都会被新来的 goroutine 获取到锁，导致等待的 goroutine 一直获取不到锁，造成饥饿问题。 type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u003c\u003c iota // mutex is locked mutexWoken mutexStarving // 从state字段中分出一个饥饿标记 mutexWaiterShift = iota starvationThresholdNs = 1e6 ) func (m *Mutex) Lock() { // Fast path: 幸运之路，一下就获取到了锁 if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { return } // Slow path：缓慢之路，尝试自旋竞争或饥饿状态下饥饿goroutine竞争 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false // 此goroutine的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前的锁的状态 for { // 锁是非饥饿状态，锁还没被释放，尝试自旋 if old\u0026(mutexLocked|mutexStarving) == mutexLocked \u0026\u0026 runtime_canSpin(iter) { if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 再次获取锁的状态，之后会检查是否锁被释放了 continue } new := old if old\u0026mutexStarving == 0 { new |= mutexLocked // 非饥饿状态，加锁 } if old\u0026(mutexLocked|mutexStarving) != 0 { new += 1 \u003c\u003c mutexWaiterShift // waiter数量加1 } if starving \u0026\u0026 old\u0026mutexLocked != 0 { new |= mutexStarving // 设置饥饿状态 } if awoke { if new\u0026mutexWoken == 0 { throw(\"sync: inconsistent mutex state\") } new \u0026^= mutexWoken // 新状态清除唤醒标记 } // 成功设置新状态 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // 原来锁的状态已释放，并且不是饥饿状态，正常请求到了锁，返回 if old\u0026(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // 处理饥饿状态 // 如果以前就在队列里面，加入到队列头 queueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // 阻塞等待 runtime_SemacquireMutex(\u0026m.sema, queueLifo, 1) // 唤醒之后检查锁是否应该处于饥饿状态 starving = starving || runtime_nanotime()-waitStartTime \u003e starvationThresholdNs old = m.state // 如果锁已经处于饥饿状态，直接抢到锁，返回 if old\u0026mutexStarving != 0 { if old\u0026(mutexLocked|mutexWoken) != 0 || old\u003e\u003emutexWaiterShift == 0 { throw(\"sync: inconsistent mutex state\") } // 有点绕，加锁并且将waiter数减1 delta := int32(mutexLocked - 1\u003c\u003cmutexWaiterShift) if !starving || old\u003e\u003emutexWaiterShift == 1 { delta -= mutexStarving // 最后一个waiter或者已经不饥饿了，清除饥饿标记 } atomic.AddInt32(\u0026m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } } func (m *Mutex) Unlock() { // Fast path: drop lock bit. new := atomic.AddInt32(\u0026m.state, -mutexLocked) if new != 0 { m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026mutexLocked == 0 { throw(\"sync: unlock of unlocked mutex\") } if new\u0026mutexStarving == 0 { old := new for { if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken|mutexStarving) != 0 { return } new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { runtime_Semrelease(\u0026m.sema, false, 1) return } old = m.state } } else { runtime_Semrelease(\u0026m.sema, true, 1) } } ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:5:2","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"思考问题 Q： 目前 Mutex 的 state 字段有几个意义，这几个意义分别是由哪些字段表示的？ A：state 字段一共有四个子字段，前三个 bit 是 mutexLocked（锁标记）、mutexWoken（唤醒标记）、mutexStarving（饥饿标记），剩余 bit 标示 mutexWaiter（等待数量）。 Q： 等待一个 Mutex 的 goroutine 数最大是多少？是否能满足现实的需求？ A：目前的设计来看取决于 state 的类型，目前是 int32，由于3个字节代表了状态，有 536870911，一个 goroutine 初始化的为 2kb，约等于 1024 GB 即 1TB，目前内存体量那么大的服务还是少有的，可以满足现在的使用。 常见错误的四种场景 Lock/Unlock 不是成对出现; Copy 已使用的 Mutex; 重入; 死锁。 ","date":"2020-11-15","objectID":"/go-concurrence-mutex/:6:0","tags":["go","concurrence","Mutex"],"title":"Go 并发编程之 Mutex","uri":"/go-concurrence-mutex/"},{"categories":["golang"],"content":"Brew 是 Mac 上包管理工具，和 Linux 上的 apt 、yum、rpm 一样，可以提供非图形化软件的安装，昨天在打造宇宙最强 IDE 的时候，使用brew工具更新了一下软件包，是我的 Go 版本升级到了最新版本，同时之前配置的多版本 Go 抹掉了，现在写一下记录，你如果需要的话可以使用一下。 之前写过一个使用 GVM 版本管理工具的文章，这个是第三方工具管理的，都比较好用，你可以根据自己的需求安装。 ","date":"2020-11-01","objectID":"/go-use-brew-switch-version/:0:0","tags":["go","brew"],"title":"优雅的使用 Brew 切换 Go 版本","uri":"/go-use-brew-switch-version/"},{"categories":["golang"],"content":"方案一 brew switch ","date":"2020-11-01","objectID":"/go-use-brew-switch-version/:1:0","tags":["go","brew"],"title":"优雅的使用 Brew 切换 Go 版本","uri":"/go-use-brew-switch-version/"},{"categories":["golang"],"content":"1 brew install brew install go ","date":"2020-11-01","objectID":"/go-use-brew-switch-version/:1:1","tags":["go","brew"],"title":"优雅的使用 Brew 切换 Go 版本","uri":"/go-use-brew-switch-version/"},{"categories":["golang"],"content":"2 brew switch ~ brew info go go: stable 1.15.3 (bottled), HEAD 使用 brew info go 命令你可以看到当前目前的 go 可以切换的版本，接下来就安装多个版本并且切换到对应的版本。 // 安装指定 go 版本 brew install go@\u003cversion\u003e // forexample brew install go@1.12.17 安装好了 之后使用 brew info go 查看是否可以切换了。 brew switch go 1.12.17 单纯的使用上面的命令你会发现，go 不能使用了，并且会出现下面的提示： ~ brew switch go 1.12.17 Cleaning /usr/local/Cellar/go/1.12.17 Cleaning /usr/local/Cellar/go/1.15.3 0 links created for /usr/local/Cellar/go/1.12.17 创建了零个连接，就代表着没有成功的将 go 版本指向你所需要的版本下，问题是什么呢？现将 go 版本切回 go 1.15.3，你会发现可以切换并正常使用： ~ brew switch go 1.15.3 Cleaning /usr/local/Cellar/go/1.12.17 Cleaning /usr/local/Cellar/go/1.15.3 3 links created for /usr/local/Cellar/go/1.15.3 ~ go version go version go1.15.3 darwin/amd64 定位这个原因你需要看看为什么没有未给 go 1.12.17 版本创建软连接，首先要找一下 go 默认安装的位置，使用 go env 查看安装目录： /usr/local/Cellar/go/ 使用 brew 工具在 MacOS Catalina 系统安装的位置。 进入到目录之后在 go 目录下只有刚才默认安装的 1.15.3 版本，并没有自己安装的版本，退出父级目录看到了下载的 go@1.12.17 版本，由于软连接连接的是上方的路径，需要将这个目录移动至 go 目录下： // 打开默认目录 cd /usr/local/Cellar/go/ // 退出目录 cd .. // 移动目录至 go 目录下 mv go@1.12.17 go/ // 重要！！！ 重命名文件夹 mv go@1.12.17 1.12.17 接下来使用切换命令 brew switch go \u003cversion\u003e 就可以切换环境了。 ","date":"2020-11-01","objectID":"/go-use-brew-switch-version/:1:2","tags":["go","brew"],"title":"优雅的使用 Brew 切换 Go 版本","uri":"/go-use-brew-switch-version/"},{"categories":["golang"],"content":"方案二 brew link 使用 Homebrew 3.2.9 验证。 1、安装新的版本： brew install go@1.16 // 安装 go 1.16 版本 2、移除原有的 go 版本软链 brew unlink go 3、指定新的版本软链 brew link go@1.16 ","date":"2020-11-01","objectID":"/go-use-brew-switch-version/:2:0","tags":["go","brew"],"title":"优雅的使用 Brew 切换 Go 版本","uri":"/go-use-brew-switch-version/"},{"categories":["golang"],"content":"近期做了一个需求，是检测某个 IP 是否在若干 IP 段内，做固定地点 IP 筛查，满足特定业务需求。 ","date":"2020-09-08","objectID":"/go-ip-segment-range-check/:0:0","tags":["go","ip"],"title":"Go IP 段范围校验","uri":"/go-ip-segment-range-check/"},{"categories":["golang"],"content":"解决方案 ","date":"2020-09-08","objectID":"/go-ip-segment-range-check/:1:0","tags":["go","ip"],"title":"Go IP 段范围校验","uri":"/go-ip-segment-range-check/"},{"categories":["golang"],"content":"PLAN A 点分十进制范围区分 简单来讲，就是将 IPv4 原有的四段，分别对比 IP 地址，查看每一段是否在 IP 段范围内，可以用于段控制在每一个特定段 0 ～ 255 内筛选，例如： 192.123.1.0 ～ 192.123.156.255 这样的比较规范的特定段可以实现简单的筛选，但是问题来了，不规则的连续 IP 段怎么排除？ 如下： IP段：192.168.1.0 ～ 192.172.3.255 IP： 192.160.0.255 这样就会出现问题，可以看到按照简单的分段对比，很明显校验不通过，但是这个 IP 还是存在在 IP 段中，方案只能针对统一分段下规则的IP段才可以区分。 ","date":"2020-09-08","objectID":"/go-ip-segment-range-check/:1:1","tags":["go","ip"],"title":"Go IP 段范围校验","uri":"/go-ip-segment-range-check/"},{"categories":["golang"],"content":"PLAN B 转整型对别 IP 地址可以转换为整数，可以将 IP 范围化整为 整数范围进行排查。 这种方式只需要将授为范围内的地址转换为整数，就可以将 IP 排查在外了。 ","date":"2020-09-08","objectID":"/go-ip-segment-range-check/:1:2","tags":["go","ip"],"title":"Go IP 段范围校验","uri":"/go-ip-segment-range-check/"},{"categories":["golang"],"content":"代码 以下是示例代码： package main import ( \"fmt\" \"strconv\" \"strings\" ) func main() { ipVerifyList := \"192.168.1.0-192.172.3.255\" ip := \"192.170.223.1\" ipSlice := strings.Split(ipVerifyList, `-`) if len(ipSlice) \u003c 0 { return } if ip2Int(ip) \u003e= ip2Int(ipSlice[0]) \u0026\u0026 ip2Int(ip) \u003c= ip2Int(ipSlice[1]) { fmt.Println(\"ip in iplist\") return } fmt.Println(\"ip not in iplist\") } func ip2Int(ip string) int64 { if len(ip) == 0 { return 0 } bits := strings.Split(ip, \".\") if len(bits) \u003c 4 { return 0 } b0 := string2Int(bits[0]) b1 := string2Int(bits[1]) b2 := string2Int(bits[2]) b3 := string2Int(bits[3]) var sum int64 sum += int64(b0) \u003c\u003c 24 sum += int64(b1) \u003c\u003c 16 sum += int64(b2) \u003c\u003c 8 sum += int64(b3) return sum } func string2Int(in string) (out int) { out, _ = strconv.Atoi(in) return } ","date":"2020-09-08","objectID":"/go-ip-segment-range-check/:2:0","tags":["go","ip"],"title":"Go IP 段范围校验","uri":"/go-ip-segment-range-check/"},{"categories":["golang"],"content":"限流器是后台服务中十分重要的组件，在实际的业务场景中使用居多，其设计在微服务、网关、和一些后台服务中会经常遇到。限流器的作用是用来限制其请求的速率，保护后台响应服务，以免服务过载导致服务不可用现象出现。 限流器的实现方法有很多种，例如 Token Bucket、滑动窗口法、Leaky Bucket等。 在 Golang 库中官方给我们提供了限流器的实现golang.org/x/time/rate，它是基于令牌桶算法（Token Bucket）设计实现的。 ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:0:0","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"令牌桶算法 令牌桶设计比较简单，可以简单的理解成一个只能存放固定数量雪糕?的一个冰箱，每个请求可以理解成来拿雪糕的人，有且只能每一次请求拿一块?，那雪糕拿完了会怎么样呢？这里会有一个固定放雪糕的工人，并且他往冰箱里放雪糕的频率都是一致的，例如他 1s 中只能往冰箱里放 10 块雪糕，这里就可以看出请求响应的频率了。 令牌桶设计概念： 令牌：每次请求只有拿到 Token 令牌后，才可以继续访问； 桶：具有固定数量的桶，每个桶中最多只能放设计好的固定数量的令牌； 入桶频率：按照固定的频率往桶中放入令牌，放入令牌不能超过桶的容量。 也就是说，基于令牌桶设计算法就限制了请求的速率，达到请求响应可控的目的，特别是针对于高并发场景中突发流量请求的现象，后台就可以轻松应对请求了，因为到后端具体服务的时候突发流量请求已经经过了限流了。 ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:1:0","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"具体设计 ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:2:0","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"限流器定义 type Limiter struct { mu sync.Mutex // 互斥锁（排他锁） limit Limit // 放入桶的频率 float64 类型 burst int // 桶的大小 tokens float64 // 令牌 token 当前剩余的数量 last time.Time // 最近取走 token 的时间 lastEvent time.Time // 最近限流事件的时间 } limit、burst 和 token 是这个限流器中核心的参数，请求并发的大小在这里实现的。 在令牌发放之后，会存储在 Reservation 预约对象中： type Reservation struct { ok bool // 是否满足条件分配了 token lim *Limiter // 发送令牌的限流器 tokens int // 发送 token 令牌的数量 timeToAct time.Time // 满足令牌发放的时间 limit Limit // 令牌发放速度 } ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:2:1","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"消费 Token Limiter 提供了三类方法供用户消费 Token，用户可以每次消费一个 Token，也可以一次性消费多个 Token。而每种方法代表了当 Token 不足时，各自不同的对应手段。 Wait、WaitN func (lim *Limiter) Wait(ctx context.Context) (err error) func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) 其中，Wait 就是 WaitN(ctx, 1)，在下面的方法介绍实现也是一样的。 使用 Wait 方法消费 Token 时，如果此时桶内 Token 数组不足 ( 小于 n )，那么 Wait 方法将会阻塞一段时间，直至 Token 满足条件。如果充足则直接返回。 Allow、AllowN func (lim *Limiter) Allow() bool func (lim *Limiter) AllowN(now time.Time, n int) bool AllowN 方法表示，截止到当前某一时刻，目前桶中数目是否至少为 n 个，满足则返回 true，同时从桶中消费 n 个 token。 反之返回不消费 Token，false。 通常对应这样的线上场景，如果请求速率过快，就直接丢到某些请求。 Reserve、ReserveN 官方提供的限流器有阻塞等待式的 Wait，也有直接判断方式的 Allow，还有提供了自己维护预留式的，但核心的实现都是下面的 reserveN 方法。 func (lim *Limiter) Reserve() *Reservation func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation 当调用完成后，无论 Token 是否充足，都会返回一个Reservation *对象。 你可以调用该对象的 Delay() 方法，该方法返回了需要等待的时间。如果等待时间为 0，则说明不用等待。 必须等到等待时间结束之后，才能进行接下来的工作。 或者，如果不想等待，可以调用 Cancel() 方法，该方法会将 Token 归还。 func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation { lim.mu.Lock() // 首先判断是否放入频率是否为无穷大 // 如果为无穷大，说明暂时不限流 if lim.limit == Inf { lim.mu.Unlock() return Reservation{ ok: true, lim: lim, tokens: n, timeToAct: now, } } // 拿到截至 now 时间时 // 可以获取的令牌 tokens 数量及上一次拿走令牌的时间 last now, last, tokens := lim.advance(now) // 更新 tokens 数量 tokens -= float64(n) // 如果 tokens 为负数，代表当前没有 token 放入桶中 // 说明需要等待，计算等待的时间 var waitDuration time.Duration if tokens \u003c 0 { waitDuration = lim.limit.durationFromTokens(-tokens) } // 计算是否满足分配条件 // 1、需要分配的大小不超过桶的大小 // 2、等待时间不超过设定的等待时长 ok := n \u003c= lim.burst \u0026\u0026 waitDuration \u003c= maxFutureReserve // 预处理 reservation r := Reservation{ ok: ok, lim: lim, limit: lim.limit, } // 若当前满足分配条件 // 1、设置分配大小 // 2、满足令牌发放的时间 = 当前时间 + 等待时长 if ok { r.tokens = n r.timeToAct = now.Add(waitDuration) } // 更新 limiter 的值，并返回 if ok { lim.last = now lim.tokens = tokens lim.lastEvent = r.timeToAct } else { lim.last = last } lim.mu.Unlock() return r } ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:2:2","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"具体使用 rate 包中提供了对限流器的使用，只需要指定 limit（放入桶中的频率）、burst（桶的大小）。 func NewLimiter(r Limit, b int) *Limiter { return \u0026Limiter{ limit: r, // 放入桶的频率 burst: b, // 桶的大小 } } 在这里，使用一个 http api 来简单的验证一下 time/rate 的强大： func main() { r := rate.Every(1 * time.Millisecond) limit := rate.NewLimiter(r, 10) http.HandleFunc(\"/\", func(writer http.ResponseWriter, request *http.Request) { if limit.Allow() { fmt.Printf(\"请求成功，当前时间：%s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")) } else { fmt.Printf(\"请求成功，但是被限流了。。。\\n\") } }) _ = http.ListenAndServe(\":8081\", nil) } 在这里，我把桶设置成了每一毫秒投放一次令牌，桶容量大小为 10，起一个 http 的服务，模拟后台 API。 接下来做一个压力测试，看看效果如何： func GetApi() { api := \"http://localhost:8081/\" res, err := http.Get(api) if err != nil { panic(err) } defer res.Body.Close() if res.StatusCode == http.StatusOK { fmt.Printf(\"get api success\\n\") } } func Benchmark_Main(b *testing.B) { for i := 0; i \u003c b.N; i++ { GetApi() } } 效果如下： ...... 请求成功，当前时间：2020-08-24 14:26:52 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 请求成功，当前时间：2020-08-24 14:26:52 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 请求成功，但是被限流了。。。 ...... 在这里，可以看到，当使用 AllowN 方法中，只有当令牌 Token 生产出来，才可以消费令牌，继续请求，剩余的则是将其请求抛弃，当然在实际的业务处理中，可以用比较友好的方式反馈给前端。 在这里，先有的几次请求都会成功，是因为服务启动后，令牌桶会初始化，将令牌放入到桶中，但是随着突发流量的请求，令牌按照预定的速率生产令牌，就会出现明显的令牌供不应求的现象。 ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:3:0","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"开源仓库 目前 time/rate 是一个独立的限流器开源解决方案，感兴趣的小伙伴可以给此项目一个 Star，谢谢。 https://github.com/golang/time ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:4:0","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["golang"],"content":"References 限流器系列(2) – Token Bucket 令牌桶 Golang 限流器的使用和实现 Golang 标准库限流器 time/rate 使用介绍 https://github.com/golang/time/rate.go ","date":"2020-08-24","objectID":"/go-standard-lib-time-rate-pkg/:5:0","tags":["go","standard lib","time rate"],"title":"Go 标准库 限流器 time/rate 设计与实现","uri":"/go-standard-lib-time-rate-pkg/"},{"categories":["mbp"],"content":"经过近两个星期的检测，维修 ?，我的 MacBook 满血复活了，事情是这样的，两周前我的电脑突然之间就黑屏，有充电反馈，键盘，Bar 和触控板均失灵，拿到公司 IT 部门，给我的意见是去售后 ?，紧接着到了周末去了售后，给我的解决方案是更换硬件，告诉我说要更换主板，也就代表着硬盘数据没有了，允悲，我同时给他说明针对于我两次修复蝶形键盘的经历，售后人员决定给我申请键盘也更换，心中多少有些安慰，于是他给了我一个维修周期，届时来领取就可以了。 于是我就拿着维修单回去了，过了两天，接到了售后的电话，我本以为修好了，并没有，售后给我说做了检测，显示器也有问题，需要给我更换，这，，，不就是更换全部的部件么，直接给我换台多效率 ?，显然苹果并没有那么给我做，现在拿到手中的就是除了下底壳没有更换，其他全部更换的九成新新机，百感交集呀。 不过，最终是修好了，在公司入职的这么多天也学习了很多东西，近期在不断的整理，后续会总结分享的，感谢一个陌生网友的关怀，?，一个高更新的博客要跑路了，虽然技术很菜，分享的技术网上一大堆，但是经验是积累的，相信自己的努力? 最终会成为大牛的，加油，嘿嘿。 ","date":"2020-08-13","objectID":"/mbp-resurrection/:0:0","tags":["mbp"],"title":"我的MacBook Pro又满血复活啦","uri":"/mbp-resurrection/"},{"categories":["golang"],"content":"RPC 在分布式计算，远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。RPC 是一种服务器-客户端（ Client/Server ）模式，经典实现是一个通过 发送请求-接受回应 进行信息交互的系统。 wiki 维基百科 在这里引用一下维基百科对于 RPC 的解释， 可以针对与 HTTP 协议来比较分析，RPC 更适合于公司中大、中型项目分布式调用场景。 ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:1:0","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"调用流程 客户端调用客户端 stub（client stub）。这个调用是在本地，并将调用参数 push 到栈（stack）中; 客户端 stub（client stub）将这些参数包装，并通过系统调用发送到服务端机器。打包的过程叫 marshalling。（常见方式：XML、JSON、二进制编码）; 客户端本地操作系统发送信息至服务器。（可通过自定义TCP协议或HTTP传输）; 服务器系统将信息传送至服务端stub（server stub）; 服务端stub（server stub）解析信息。该过程叫 unmarshalling; 服务端stub（server stub）调用程序，并通过类似的方式返回给客户端。 ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:1:1","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"RPC 与 HTTP 区别 RPC 调用实现的方式是和 HTTP 有异曲同工之处的，但是对于 RPC 与 HTTP 在 请求 / 响应中还是存在着差别的： HTTP 与 RPC 协议在实现上是不同的，大家都了解到 HTTP 原理就是 客户端请求服务端，服务端去响应并返回结果，但是 RPC 协议设计的时候采用的方式就是服务端给客户端提供 TCP 长连接服务，Client 端去调用 Server 提供的接口，实现特定的功能； RPC 可以同时提供同步调用及异步调用，而 HTTP 提供的方式就是同步调用，客户端会等待并接受服务端的请求处理的结果； RPC 服务设计可以提高代码编写过程中的解耦操作，提高代码的可移植性，每一个 服务可以设计成提供特定功能的小服务，客户端去调取远程的服务，而不用去关心远程是怎么实现的。 ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:2:0","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"RPC 应用领域 大型网站的内部子系统设计； 为系统提供降级功能； 并发设计场景； 当然 RPC 也有缺点，每一个 RPC 服务都需要单独搭建，一旦服务出错或者更为严重的不提供支持，作为客户端的就会出现服务不可用，这对系统稳定性及可持续提供支持要求比较高，当然在设计过程中，这样也加大了对系统调试的难度，也就是说这种设计要求 RPC 服务的稳定性及正确性要求是比较大的。 ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:2:1","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"实现代码 ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:3:0","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"客户端实现 package main import ( \"demo/common\" \"fmt\" \"net/rpc\" ) func main() { var args = common.Args{A: 32, B: 14} var result = common.Result{} var client, err = rpc.DialHTTP(\"tcp\", \"127.0.0.1:9090\") if err != nil { fmt.Printf(\"connect rpc server failed, err:%v\", err) } err = client.Call(\"MathService.Divide\", args, \u0026result) if err != nil { fmt.Printf(\"call math service failed, err:%v\", err) } fmt.Printf(\"call RPC server success, result:%f\", result.Value) } ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:3:1","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"服务端实现 package main import ( \"demo/common\" \"fmt\" \"net/http\" \"net/rpc\" ) func main() { var ms = new(common.MathService) // 注册 RPC 服务 err := rpc.Register(ms) if err != nil { fmt.Printf(\"rpc server register faild, err:%s\", err) } // 将 RPC 服务绑定到 HTTP 服务中去 rpc.HandleHTTP() fmt.Printf(\"server start ....\") err = http.ListenAndServe(\":9090\", nil) if err != nil { fmt.Printf(\"listen and server is failed, err:%v\\n\", err) } fmt.Printf(\"server stop ....\") } ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:3:2","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"功能实现 package common import \"errors\" type Args struct { A, B float32 } type Result struct { Value float32 } type MathService struct {} func (s *MathService) Add (args *Args, result *Result) error{ result.Value = args.A + args.B return nil } func (s *MathService) Divide(args *Args, result *Result) error{ if args.B == 0 { return errors.New(\"arge.B is 0\") } result.Value = args.A / args.B return nil } ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:3:3","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"References 简述RPC原理实现 - 博客园 Http和RPC区别 远程过程调用 - 维基百科 直观讲解–RPC调用和HTTP调用的区别 ","date":"2020-08-01","objectID":"/go-rpc-invoke-demo/:4:0","tags":["go","rpc","invoke"],"title":"Go 语言实现 RPC 调用","uri":"/go-rpc-invoke-demo/"},{"categories":["golang"],"content":"在 Go 项目开发中，团队要保持开发版本一致，怎么能够快速的安装及部署并且切换 Go 环境，在这里推荐一款工具 GVM （ Go Version Manager ），它可以便捷切换与自定义 Go Path 、Go Root 等参数，是一款实打实的多版本安装及管理利器。 GVM，类似于ruby 中的 RVM，java 中的 jenv（国产），可用于方便管理 Go 的版本，它有如下几个主要特性： 管理 Go 的多个版本，包括安装、卸载和指定使用 Go 的某个版本； 查看官方所有可用的 Go 版本，同时可以查看本地已安装和默认使用的 Go 版本； 管理多个 GOPATH，并可编辑 Go 的环境变量； 可将当前目录关联到 GOPATH； 可以查看 GOROOT 下的文件差异。 ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:0:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"安装 Installing bash \u003c \u003c(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 或者，如果您使用的是 zsh，只需使用 zsh 更改 bash。 ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:1:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"使用 GVM 使用 gvm 可以查看支持的操作： ➜ ~ gvm Usage: gvm [command] Description: GVM is the Go Version Manager Commands: version - print the gvm version number get - gets the latest code (for debugging) use - select a go version to use (--default to set permanently) diff - view changes to Go root help - display this usage text implode - completely remove gvm install - install go versions uninstall - uninstall go versions cross - install go cross compilers linkthis - link this directory into GOPATH list - list installed go versions listall - list available versions alias - manage go version aliases pkgset - manage go packages sets pkgenv - edit the environment for a package set ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:2:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"安装 Go 版本 例如安装 go1.13 版本： gvm install go1.13 ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:3:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"查看 Go 版本 ➜ ~ gvm list gvm gos (installed) go1.12 =\u003e system ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:4:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"切换 Go 版本 gvm use go1.** ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:5:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"管理 Gopath 环境 GVM 提供了一个比较简单的工具 gvm pkgset 可以创建使用 GOPATH 环境： ➜ ~ gvm pkgset = gvm pkgset * http://github.com/moovweb/gvm == DESCRIPTION: GVM pkgset is used to manage various Go packages == Usage gvm pkgset Command == Command create - create a new package set delete - delete a package set use - select where gb and goinstall target and link empty - remove all code and compiled binaries from package set list - list installed go packages ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:6:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"卸载 Uninstall 卸载某个安装好的 Go 版本： gvm uninstall go1.13 ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:7:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"开源代码 GVM 是一款使用 Shell 脚本实现的便捷工具，作为开源项目，推荐大家给一个 Star 支持。 https://github.com/moovweb/gvm ","date":"2020-07-12","objectID":"/go-use-gvm-switch-version/:8:0","tags":["go","gvm"],"title":"使用 GVM 工具管理 Go 版本","uri":"/go-use-gvm-switch-version/"},{"categories":["golang"],"content":"SQLX 库 sqlx是 Go 的软件包，它在出色的内置database/sql软件包的基础上提供了一组扩展。 该库兼容 sql 原生包，同时又提供了更为强大的、优雅的查询、插入函数。 该库提供四个处理类型，分别是： sqlx.DB - 类似原生的sql.DB； sqlx.Tx - 类似原生的sql.Tx； sqlx.Stmt - 类似原生的 sql.Stmt, 准备 SQL 语句操作； sqlx.NamedStmt - 对特定参数命名并绑定生成 SQL 语句操作。 提供两个游标类型，分别是： sqlx.Rows - 类似原生的 sql.Rows, 从 Queryx 返回； sqlx.Row - 类似原生的 sql.Row, 从 QueryRowx 返回。 ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:1:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"安装 SQLX 库 go get github.com/jmoiron/sqlx ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:2:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"使用操作 ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:3:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"连接数据库 // 初始化数据库 func initMySQL() (err error) { dsn := \"root:password@tcp(127.0.0.1:3306)/database\" db, err = sqlx.Open(\"mysql\", dsn) if err != nil { fmt.Printf(\"connect server failed, err:%v\\n\", err) return } db.SetMaxOpenConns(200) db.SetMaxIdleConns(10) return } SetMaxOpenConns 和 SetMaxIdleConns 分别为设置最大连接数和最大空闲数。 ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:3:1","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"数据表达及引用 在这里提前声明一个用户结构体 user，将 *sqlx.DB 作为一个全局变量使用，当然也要提前引用 MySQL 的驱动包，如下设计： import ( \"fmt\" _ \"github.com/go-sql-driver/mysql\" \"github.com/jmoiron/sqlx\" ) var db *sqlx.DB type user struct { Id int `db:\"id\"` Age int `db:\"age\"` Name string `db:\"name\"` } ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:4:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"查询操作 ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:5:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"查询一行数据 查询一行数据使用 sqlx 库中的 Get 函数实现： func (db *DB) Get(dest interface{}, query string, args ...interface{}) error dest 是用户声明变量接收查询结果，query 为查询 SQL 语句，args 为绑定参数的赋值。 // 查询一行数据 func queryRow() { sqlStr := \"SELECT id, name, age FROM user WHERE id = ?\" var u user if err := db.Get(\u0026u, sqlStr, 1); err != nil { fmt.Printf(\"get data failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d, name:%s, age:%d\\n\", u.Id, u.Name, u.Age) } ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:5:1","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"查询多行数据 而查询多行数据则使用的是Select 函数： func (db *DB) Select(dest interface{}, query string, args ...interface{}) error 使用 Select 函数进行查询的时候，需要先声明一个结构体数组接收映射过来的数据： // 查询多行数据 func queryMultiRow() { sqlStr := \"SELECT id, name, age FROM user WHERE id \u003e ?\" var users []user if err := db.Select(\u0026users, sqlStr, 0); err != nil { fmt.Printf(\"get data failed, err:%v\\n\", err) return } for i := 0; i \u003c len(users); i++ { fmt.Printf(\"id:%d, name:%s, age:%d\\n\", users[i].Id, users[i].Name, users[i].Age) } } ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:5:2","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"插入、更新、删除操作 在 sqlx 库中，使用插入、更新、删除操作是和原生 sql 库实现是一致的，都是采用 Exec 函数来实现的： 插入操作 // 插入数据 func insertRow() { sqlStr := \"INSERT INTO user(name, age) VALUES(?, ?)\" result, err := db.Exec(sqlStr, \"Meng小羽\", 22) if err != nil { fmt.Printf(\"exec failed, err:%v\\n\", err) return } insertID, err := result.LastInsertId() if err != nil { fmt.Printf(\"get insert id failed, err:%v\\n\", err) return } fmt.Printf(\"insert data success, id:%d\\n\", insertID) } 更新操作 // 更新数据 func updateRow() { sqlStr := \"UPDATE user SET age = ? WHERE id = ?\" result, err := db.Exec(sqlStr, 22, 6) if err != nil { fmt.Printf(\"exec failed, err:%v\\n\", err) return } affectedRows, err := result.RowsAffected() if err != nil { fmt.Printf(\"get affected failed, err:%v\\n\", err) return } fmt.Printf(\"update data success, affected rows:%d\\n\", affectedRows) } 删除操作 // 删除一行 func deleteRow() { sqlStr := \"DELETE FROM user WHERE id = ?\" result, err := db.Exec(sqlStr, 4) if err != nil { fmt.Printf(\"exec failed, err:%v\\n\", err) return } affectedRows, err := result.RowsAffected() if err != nil { fmt.Printf(\"get affected failed, err:%v\\n\", err) return } fmt.Printf(\"delete data success, affected rows:%d\\n\", affectedRows) } 参数绑定 在库中提供最常用的就是NamedQuery和NamedExec函数，一个是执行对查询参数命名并绑定，另一个则是对 CUD 操作的查询参数名的绑定： NamedQuery // 绑定查询 func selectNamedQuery() { sqlStr := \"SELECT id, name, age FROM user WHERE age = :age\" rows, err := db.NamedQuery(sqlStr, map[string]interface{}{ \"age\": 22, }) if err != nil { fmt.Printf(\"named query failed failed, err:%v\\n\", err) return } defer rows.Close() for rows.Next() { var u user if err := rows.StructScan(\u0026u); err != nil { fmt.Printf(\"struct sacn failed, err:%v\\n\", err) continue } fmt.Printf(\"%#v\\n\", u) } } NamedExec // 使用 named 方法插入数据 func insertNamedExec() { sqlStr := \"INSERT INTO user(name, age) VALUES(:name, :age)\" result, err := db.NamedExec(sqlStr, map[string]interface{}{ \"name\": \"里斯\", \"age\": 18, }) if err != nil { fmt.Printf(\"named exec failed, err:%v\\n\", err) return } insertId, err := result.LastInsertId() if err != nil { fmt.Printf(\"get last insert id failed, err:%v\\n\", err) return } fmt.Printf(\"insert data success, id:%d\\n\", insertId) } 事务操作 使用Begin函数、Rollback函数及Commit函数实现事务操作： // 开启事务 func (db *DB) Begin() (*Tx, error) // 回滚事务 func (tx *Tx) Rollback() error // 提交事务 func (tx *Tx) Commit() error 示例代码： // 事务操作 func updateTransaction() (err error) { tx, err := db.Begin() if err != nil { fmt.Printf(\"transaction begin failed, err:%v\\n\", err) return err } defer func() { if p := recover(); p != nil { _ = tx.Rollback() panic(p) } else if err != nil { fmt.Printf(\"transaction rollback\") _ = tx.Rollback() } else { err = tx.Commit() fmt.Printf(\"transaction commit\") return } }() sqlStr1 := \"UPDATE user SET age = ? WHERE id = ? \" reuslt1, err := tx.Exec(sqlStr1, 18, 1) if err != nil { fmt.Printf(\"sql exec failed, err:%v\\n\", err) return err } rows1, err := reuslt1.RowsAffected() if err != nil { fmt.Printf(\"affected rows is 0\") return } sqlStr2 := \"UPDATE user SET age = ? WHERE id = ? \" reuslt2, err := tx.Exec(sqlStr2, 19, 5) if err != nil { fmt.Printf(\"sql exec failed, err:%v\\n\", err) return err } rows2, err := reuslt2.RowsAffected() if err != nil { fmt.Printf(\"affected rows is 0\\n\") return } if rows1 \u003e 0 \u0026\u0026 rows2 \u003e 0 { fmt.Printf(\"update data success\\n\") } return } ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:5:3","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"开源项目 最后将此开源项目放在此处，大家要是感兴趣可以给这个开源项目一个 Star，感谢。 https://github.com/jmoiron/sqlx ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:6:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["golang"],"content":"References http://jmoiron.github.io/sqlx/ sqlx库使用指南 - 李文周的博客 ","date":"2020-07-07","objectID":"/go-mysql-sqlx-pkg/:7:0","tags":["go","mysql"],"title":"Go 语言操作 MySQL 之 SQLX 包","uri":"/go-mysql-sqlx-pkg/"},{"categories":["os"],"content":"中央处理器CPU 单机系统： 一个计算机系统只有一个处理器。 多处理器系统： 一个计算机系统有多个处理器。 ","date":"2017-11-20","objectID":"/os-runtime/:1:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"CPU的构成与基本工作方式 处理器一般由运算器、控制器、寄存器以及高速缓存构成。 运算器 实现任何指令中的算术和逻辑运算，是计算机的核心; 控制器 负责控制程序运行的流程，包括取指令、维护CPU状态、CPU与内存的交互等; 寄存器 是指令在CPU内部做处理的过程中能够张村数据、地址以及指令信息的存储设备; 高速缓存 处于CPU和物理内存之间，一般由控制器中的内存管理单元MMU管理; ","date":"2017-11-20","objectID":"/os-runtime/:2:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"处理器中的寄存器 用户可见存储器：对于高级语言来说，编译器通过一定的算法分配并使用这些寄存器，以最大限度地减少程序运行过程中的访问存储器的次数，这对程序运行速度的影响很大。 控制和状态存储器：用于控制处理器的操作。 数据寄存器：又称为通用寄存器，主要用于各种算术逻辑指令和访存指令，对具有浮点能力和多媒体能力处理能力的处理器来说，浮点处理过程的数据寄存器和整数处理时的数据寄存器一般是分离的。 地址寄存器：用于存储数据及指令的物理地址、线性地址、有效地址。 条形码寄存器：保存CPU操作结果的各种标记位。 作用：控制处理器的操作。 控制和状态寄存器包括了程序计数器、指令寄存器和程序状态字。 程序计数器（PC）：记录了将要取出的指令的地址。 指令寄存器（IR）：包含了最近取出的指令。 程序状态字（PSW）：记录了处理器的运行模式信息。 ","date":"2017-11-20","objectID":"/os-runtime/:2:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"指令执行的基本过程 处理指令的最简单的方式包括两种步骤：处理器先从存储器中每次读取一条指令，然后执行这条指令。 这些指令大致分为以下五类： 访问存储器指令：负责处理器和存储器之间的数据传送。 I/O指令：负责处理器与I/O模块之间的数据传输及命令发送。 算术逻辑指令：又称为数据处理指令，用以执行有关数据的算术与逻辑操作。 控制转移指令：可以指令一个新的指令的执行起点。 处理器控制指令：用于修改处理器状态，改变处理器工作方式。 例： 假设程序计数器PC正指向2000h地址处的指令，指令机器描述如下： 地址 指令 2000h MOVE [3340h], R1 2004h ADD R1, 1 2008h MOVE R1, [3340h] …… …… …… …… 指令MOVE被送入指令寄存器IR中，同时将自增一个指令的长度，（4个字节），取指之后PC为2004h。 这是一条访问内存的指令，树3340h所指定的双字地址单元中的数据取到通用寄存器R1中来。 CPU又从PC（地址为2004h）处取出指令ADD到IR中，PC变为2008h。 CPU根据指令将R1寄存器和立即数1相加。 访存指令MOVE被取到IR中，PC变为2004h。 ","date":"2017-11-20","objectID":"/os-runtime/:2:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"特权指令与非特权指令 单用户单任务下使用计算机指令系统中的全部命令。 多用户多任务中，分为：特权模式和非特权模式。 特权指令 ：是指指令系统中那些只能用操作系统使用的指令，这些特权指令是不允许一般的用户所使用的。 用户只能使用非特权指令，因为只有操作系统才能使用所有的指令。 ","date":"2017-11-20","objectID":"/os-runtime/:2:3","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"处理器的状态 ","date":"2017-11-20","objectID":"/os-runtime/:3:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"管态与目态 管态 ：指操作系统管理程序运行的状态，具有较高的特权级别，又称特权态、系统态。 目态： 指用户程序运行时的状态，具有较低的特权级别，又称普通态、用户态。 例： 英特尔X86系列处理器特权级别 R0：运行操作系统的核心代码 R1：运行关键设备驱动程序和I/O处理例程 R2：运行其他受保护的贡献代码 R3：运行各种用户程序 R0到R3特权能力依次降低，R0相当于双状态系统的管态，R3相当于目态，而R1和R2则介于两者之间。 ","date":"2017-11-20","objectID":"/os-runtime/:3:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"CPU 状态的转换 目态到管态的转换，权限提升 管态到目态的转换，可以通过设置PSW指令（修改程序状态字），实现从操作系统向用户程序的转换。 ","date":"2017-11-20","objectID":"/os-runtime/:3:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"限制用户程序执行特权指令 ","date":"2017-11-20","objectID":"/os-runtime/:3:3","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"程序状态字 PSW 程序状态字PSW：用程序计数器PC这个专门的寄存器来指示下一条要执行的指令。 PSW包括以下状态代码： CPU的工作状态码 条件码 中断屏蔽码 某些常见标志位： CF：进位标志位 ZF：结构为零标志位 SF：符号标志位 OF：溢出标志位 TF：陷阱标志位 IF：中断使能标志位 VIF：虚拟中断标志位 VIP：虚拟中断带决标志位 IOPL：IO特权级别 ","date":"2017-11-20","objectID":"/os-runtime/:4:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"存储体系 一个作业必须把它的程序和数据存放在主存储器中才能运行。 ","date":"2017-11-20","objectID":"/os-runtime/:5:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"存储器的层次结构 设计主要考虑三方面：容量、速度和成本。 容量是存储系统的基础。 速度存储系统的速度则要能匹配处理器的速度。 存储器的成本和其他部件相比应该在一个合适的范围内。 ","date":"2017-11-20","objectID":"/os-runtime/:5:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"容量、速度和成本的匹配 存储速度越快，平均每比特价格越高，容量越小，平均每比特的价格越低，同时容量也增大。 ","date":"2017-11-20","objectID":"/os-runtime/:5:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"存储访问局部性原理 ","date":"2017-11-20","objectID":"/os-runtime/:5:3","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"存储保护 ","date":"2017-11-20","objectID":"/os-runtime/:6:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"界地址寄存器（界限寄存器） 在CPU中设置一队界限寄存器来存放用户作业在主存中的下限和上限地址，分别称为下限寄存器和上限寄存器。指出程序在内存的存放位置。 越界中断又称存储保护中断，每当CPU要访问主存时，硬件自动被访问的主存地址与界限存储器的内容进行比较，以判断是否越界。如果未越界，则按此地址访问主存，否则将产生程序中断。 ","date":"2017-11-20","objectID":"/os-runtime/:6:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"存储键 每个存储块都有一个与其相关的由二进位组成的存储保护键。 每当一个用户作业被允许进入主存时，操作系统分给他一个唯一的、不与其他作业相同的存储键号；并将分配该作业的各存储快的存储键，也设置成同样的键号。操作系统同时将该作业的存储键号存放到程序状态字PSW的存储键域中，这样，每当CPU访问主存时，都将对主存块的存储键与PSW中的钥匙进行比较。如果相比配，则允许访问；否则，拒绝并报警。 ","date":"2017-11-20","objectID":"/os-runtime/:6:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"中断和异常机制 ","date":"2017-11-20","objectID":"/os-runtime/:7:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"中断与异常 中断 指CPU对系统中或者系统外发生的异步事件的响应。 异步事件 是指无一定时间关系的随机发生的事件。 中断是所有要打断处理器的正常工作次序，并要求其去处理某一事件的一种手段。 中断事件：又称中断源，引起中断的事件。 中断请求：中断源向处理器发出的请求信号。 中断处理程序：处理中断事件的程序。 中断断点：处理器暂时当前程序转而处理中断的过程。 中断响应：处理器暂停当前程序转而处理中断的过程。 中断返回：中断处理结束后恢复原来程序的执行。 中断字一个计算机系统提供的中断源的有序集合。 中断向量表：中断处理程序入口地址映射表。 中断向量：表中的每一项，主要是由程序状态字PSW和指令计数器PC的值组成。 中断是由外部事件引发的。 异常则是由正在执行的指令引发的。 ","date":"2017-11-20","objectID":"/os-runtime/:7:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"中断与异常的分类 中断 时钟中断：是由处理器内部的计时器产生。 输入输出（I/O）中断：正常完成或则发生的错误。 控制台中断：如系统操作员通过控制台发出的命令。 硬件故障中断：由掉电、存储器校验错等硬件故障引起的。 异常 程序性中断：由指令执行结果产生。 访问指令异常：要求操作系统提供系统服务。 ","date":"2017-11-20","objectID":"/os-runtime/:7:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"中断系统 中断系统：是由硬件及软件相互配合、相互渗透而使得计算机系统得以充分发挥能力的计算机模式。 中斷系統的硬件中断装置和软件中断处理程序。硬件终端装置负责捕获中断源发出的中断请求，并以一定的方式响应中断源，然后将处理器的控制权移交给特定的中断处理程序.中断处理程序就是针对中断事件的性质而执行的一系列操作。 ","date":"2017-11-20","objectID":"/os-runtime/:8:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"中断请求的接受 中断请求的接受是通过在计算机硬件上的终端逻辑线路和中断寄存器实现的。 触发器的值为1时，表示该触发器接收到了中断信号，为0时表示无中断信号。 中断响应 响应机制：处理器控制不见中的设置有中断信号扫描结构，它在每条指令执行周期内的最后时刻扫描出中断寄存器，查看是否有中断信号的到来。 有中断到来=》处理器结构硬件终端装置发来的中断向量代号。 无中断到来=》处理器就继续执行下一条指令。 中断请求响应的工作过程： 处理器接受中断信号 保护现场个，将中断断点的程序状态字PSW和程序计数器PC值存入系统堆栈。 分析中断向量，取得中断向量程序的入口程序。 将处理器的PC值置为中断处理程序的入口地址。 调解中断处理程序。 中断处理 接受和响应中断。 保护中断现场。 分析中断向量。 调用中断处理程序。 中断处理结束恢复现场。 原有程序继续执行。 几种典型的中断的处理 I/O中断：一般是由I/O设备的控制器或者通道发出。 时钟中断 维护软件时钟 处理器调度 控制系统定时任务 实时处理 硬件故障中断：一般是由硬件的问题引起的。例如复位硬件或者更换设备。 程序性中断：程序指令出错、指令越权或者指令寻址越界而引发的系统保护。 系统服务请求（访管中断）：应用程序设计接口API。 ","date":"2017-11-20","objectID":"/os-runtime/:8:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"中断优先级与终端屏蔽 多级中断与中断优先级 硬件上，多级中断系统表现为有多根中断请求线从不同设备连接到中断逻辑线路上。 各类中断信号依据其紧急程度和重要性划分级别。 解决如果有重要程度相当的多个中断信号同时到达时，如何选择首个被处理的中断信号的问题。 中断屏蔽 在整个中断系统中，可以允许或则禁止中断系统对某些类别中断的响应。 在程序状态字PSW中设计有中断屏蔽位，主机是否允许响应或禁止某些中断，则由PSW中的中断屏蔽位决定，这些屏蔽位标识了那些被屏蔽中断类或者中断。 例：在一个计算机系统中，CD-ROM到硬盘的数据传输的优先级低于硬盘内部的数据传输操作。 内存奇偶检验错，以及掉电等使得机器无法继续操作的一类故障。一旦发生这类不可屏蔽的中断，不管程序状态字的屏蔽位是否建立，处理器都要立即相应这类中断，并进行处理。 ","date":"2017-11-20","objectID":"/os-runtime/:8:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"系统调用 ","date":"2017-11-20","objectID":"/os-runtime/:9:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"系统调用 系统调用就是用户在程序中调用操作系统所提供的一系列子功能。 有特殊的机器指令实现的，由汇编语言直接访问。 系统调用与一般过程调用的区别 运行在不同的系统状态：调用程序运行在用户态，而被调用程序则运行在系统态。 状态的转换：通过软中断机制先由用户态转换为核心态，在操作系统核心分析之后，转向相应的系统调用处理子程序。 返回问题：让优先级最高的进程优先执行。 嵌套调用：在一个被调用的过程执行期间，还可在利用系统调用命令在去调用另一个系统调用。 系统调用的分类 进程控制类系统调用：对进程的控制，如创建和终止进程的系统调用。 文件操作类系统调用：对文件进行操作的系统调用，如创建、打开、关闭、读写文件等操作。 进程通信类系统调用：被用在进程之间传递信息和信号。 设备管理类系统调用：系统调用被用来请求和释放有关设备，以及启动设备操作。 信息维护类系统调用：有关信息维护的系统调用。 系统调用命令是作为扩充机器指令，增强系统的功能，方便用户使用而提供的。 “广义指令”：系统调用命令的过程。软件实现的 ","date":"2017-11-20","objectID":"/os-runtime/:9:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"系统调用的处理过程 在系统中为控制系统调用服务的机构称为陷入（TRAP）或异常处理机构。 由于系统调用引起的处理机中断的指令称为陷入或异常指令（或称访管指令）。 一种是由陷入指令自带的参数。 另一种是通过有关通用寄存器来传递参数。 处理机在用户程序中执行称为用户态，而把处理机在系统程序中执行称为系统态（或管态）。 ","date":"2017-11-20","objectID":"/os-runtime/:9:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"I/O技术 ","date":"2017-11-20","objectID":"/os-runtime/:10:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"I/O结构 通道 通道是独立于中央处理器的，专门负责数据I/O传输工作的处理单元。 I/O处理机通道对外部设备实行统一的管理，代替CPU对I/O设备操作进行控制。 工作原理： 按程序规定的顺序执行一条条指令，按指令中给定的参数启动指定的设备。 控制权转移到通道 信息传送，由通道控制，而中央处理器则继续执行程序。 产生一个“输入输出操作结束”的I/O中断事件。 ","date":"2017-11-20","objectID":"/os-runtime/:10:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"DMA 技术 直接存储器访问DMA技术通过系统总线中的一个独立的控制单元，自动的控制成块的数据在内存和I/O单元之间的传送， DMA控制单元命令包含了I/O设备的编址、开始读或写的主存编址、需要传送的数据长度、是否请求一次读和写等信息。 ","date":"2017-11-20","objectID":"/os-runtime/:10:2","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"缓冲技术 缓冲技术实在外部设备于其他硬件之间的一种数据暂存技术，他利用存储器件在外部设备中设置了数据的一个存储区域，称为缓冲区。 两种用途： 在外部设备与外部设备之间的通信上。 在外部设备和处理器之间。 最根本原因：CPU处理数据的速度与设备传输数据速度不相匹配，需要缓冲区缓解其间的速度矛盾。 ","date":"2017-11-20","objectID":"/os-runtime/:10:3","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"时钟 ","date":"2017-11-20","objectID":"/os-runtime/:11:0","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["os"],"content":"时钟的作用 在多道程序运行的环境中，防止时机的浪费。 在分时系统中，用时钟间隔来实现各个作业按时间片轮转运行。 在实时系统中，按要求的时间间隔输出争取的时间信号给相关的实时控制设备。 定时唤醒哪些要求按照事先给定的时间执行的各个外部事件。 记录用户使用各种设备的时间和记录某外部事件发生的时间间隔。 记录用户和系统所需要的绝对时间，即年月日。 时钟一般分为硬件时钟和软件时钟。 硬件时钟工作原理：在电路中的晶体震荡器，每个一定的时间间隔产生固定的脉冲频率，时钟电路中的时钟寄存器依据时钟电路所产生的脉冲数，对时钟寄存器进行加1操作。 软件时钟工作原理：主要是利用内存单元模拟时钟寄存器，并采用一段程序来计算相应的脉冲数，对内存时钟寄存器进行加1或减1操作。 时钟的用途可以分为绝对时钟和相对时钟。 绝对时钟是在计算机系统中不受外界干扰、独立运行的一种时钟。 相对时钟又称“间隔时钟”，它只计算从某一个时间初值开始的一段时间间隔。 ","date":"2017-11-20","objectID":"/os-runtime/:11:1","tags":["os","runtime","操作系统","学习笔记"],"title":"操作系统 运行机制","uri":"/os-runtime/"},{"categories":["algorithm"],"content":"算法原理 先确定待查记录所在的范围（区间），然后逐步缩小范围指导找到或找不到该记录为止。 ","date":"2017-11-18","objectID":"/half-search/:1:0","tags":["笔记","数据结构"],"title":"数据结构 折半查找法","uri":"/half-search/"},{"categories":["algorithm"],"content":"算法性能 时间复杂度： log 2 n + 1 平均查找长度： log 2 n + 1 – 1 ","date":"2017-11-18","objectID":"/half-search/:2:0","tags":["笔记","数据结构"],"title":"数据结构 折半查找法","uri":"/half-search/"},{"categories":["algorithm"],"content":"注意事项 折半查找法必须为有序数列。 可以是逆序的，但是必须得提前定义遍历对比对象。 ","date":"2017-11-18","objectID":"/half-search/:3:0","tags":["笔记","数据结构"],"title":"数据结构 折半查找法","uri":"/half-search/"},{"categories":["algorithm"],"content":"算法实现 include \"stdio.h\" //折半查找函数 int binarySearch(int a[], int n, int key){ //定义数组的第一个数 int low = 0; //定义数组的最后一个数 int high = n-1; //定义中间的数值 int mid; //存放中间的数值的变量 int midVal; //当左边的值小于等于右边的值的时候 while(low \u003c= high){ mid = (low + high)/2; midVal = a[mid]; //如果中间值小于用户查找到的数值，最低的数字到中间数值+1位置上 if(midVal \u003c key){ low = mid + 1; }else if(midVal \u003e key){ //如果中间值大于用户查找到的数值，最高的数字到中间数值-1位置上 high = mid - 1; } else return mid; } return -1; } int main(){ int i, val, ret; int a[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; //打印数组 for(i=0; i\u003c10; i++) printf(\"%d \\t\", a[i]); printf(\"\\n请你输入你要进行查找的元素\\n\"); scanf(\"%d\", \u0026val); ret = binarySearch(a, 10, val); if(ret == -1){ printf(\"查找失败！\\n\"); } else{ printf(\"查找成功！\\n\"); } return 0; } ","date":"2017-11-18","objectID":"/half-search/:4:0","tags":["笔记","数据结构"],"title":"数据结构 折半查找法","uri":"/half-search/"},{"categories":["os"],"content":"操作系统的概念 ","date":"2017-11-18","objectID":"/os-introduction/:1:0","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"计算机系统 计算机系统包括硬件子系统及软件子系统。 各种程序和数据组成了计算机的软件系统。 操作系统：在计算机系统中，集中了资源管理功能和控制程序执行功能的一种软件。 ","date":"2017-11-18","objectID":"/os-introduction/:1:1","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"操作系统的定义 “有效”是指根据用户的不同的要求，在管理计算机资源时考虑到系统运行的效率及资源的利用率。 “合理”是指操作系统要“公平对待”不同的用户程序，保证系统不发生“死锁”及“饥饿”现象。 ","date":"2017-11-18","objectID":"/os-introduction/:1:2","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"操作系统的特征 并发性 是指在计算机系统中同时存在若干个运行的程序。计算机的并发行体现在下面两个方面： 用户程序与用户程序之间并发执行 用户程序与操作系统之间并发执行 共享性 随机性 ","date":"2017-11-18","objectID":"/os-introduction/:1:3","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"研究操作系统的观点 软件的观点 操作系统就是一种大型的软件系统，它是多种功能程序的集合。 外在特性 操作系统是一种软件，它的外部表现形式，即它的操作命令定义集和它的界面，完全确定了炒作系统这个软件的使用方式。 内在特性 操作系统既然是臃肿软件，他就具有一般软件的结构特点。 资源管理的观点操作系统就是负责记录谁在使用什么样的资源。 操作系统要提供一些机制去协调程序间的竞争与同步，提供机制对资源进行合理使用，对其保护，一机采取虚拟技术来“扩充”资源等。 进程的观点 操作系统就死看作是由多个可以独立运行的程序和一个对这些程序进行协调的核心所组成的。 虚拟机的观点 服务提供者的观点 ","date":"2017-11-18","objectID":"/os-introduction/:1:4","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"操作系统的功能 进程管理 对中央处理器进行管理。 进程管理分为一下几个方面： 进程控制进程控制的主要任务就是创建进程、撤销结束的进程以及控制进程进行时候的各种状态的转换。 进程同步 互斥 ：是指多个进程对临界资源访问时采用互斥的形式。 同步 ：是在相互协作共同完成任务进程之间，用同步机制协调他们之间的执行顺序。 进程间通讯进程通讯主要发生在相互协作的进程之间。由操作系统提供给的进程间的通讯机制是协作的进程之间相互交换数据和消息的手段。 调度 调度又称处理器调度，通常包括进程调度、线程调度及作业调度。 进程调度 任务就是从进程（线程）的就绪队列中按照一定的算法挑选出一个，吧处理器资源分配给他，并准备好特定的执行上下文让他执行起来。 作业调度 依照作业说明书为他们分配一定的资源，把他们装进内存并未每个作业建立相应的进程。 存储管理存储管理的任务就是管理计算机内存的资源。 文件管理 文件管理的任务就是有效的支持文件的存储、检索及修改等操作，解决文件的共享、保密及保护问题，以使用户方便、安全的访问文件。 设备管理 用户接口 用户计算机系统之间的接口。 ","date":"2017-11-18","objectID":"/os-introduction/:1:5","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"操作系统的发展 ","date":"2017-11-18","objectID":"/os-introduction/:2:0","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"手工操作 通过在插板上的硬连接线来控制计算机的基本功能。 ","date":"2017-11-18","objectID":"/os-introduction/:2:1","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"监控程序（早期批处理） ","date":"2017-11-18","objectID":"/os-introduction/:2:2","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"多道批处理 多道 是指允许多个程序同时存在于内存之中，由CPU以切换的方式为之服务，使得多个程序可以同时执行。 ","date":"2017-11-18","objectID":"/os-introduction/:2:3","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"分时系统 分时系统 是指多个用户通过终端设备与计算机交互作用来运行自己的作业，并且共享一个计算机系统而互不干扰。 ","date":"2017-11-18","objectID":"/os-introduction/:2:4","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"UNIX通用操作系统 C语言编写。 ","date":"2017-11-18","objectID":"/os-introduction/:2:5","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"个人计算机操作系统 ","date":"2017-11-18","objectID":"/os-introduction/:2:6","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"Android操作系统 ","date":"2017-11-18","objectID":"/os-introduction/:2:7","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"操作系统分类 批处理操作系统 批处理操作系统特点就是成批处理。 作业吞吐率：在单位时间内计算机系统处理作业的个数。 设计思想 在监控程序启动之前，操作员有选择的把若干作业合并成一批作业，将这些作业安装在输入设备之上，然后自动监控程序，监控程序将自动控制这批作业执行。 一般指令与特权指令 运行模式通常分为用户模式和特权模式。 目态： 为用户服务的用户模式。 管态： 为系统专用的特权模式。 系统调用的过程 系统调用时，通常是中断或者异常处理，将处理器模式转变成特权模式。 由监控程序执行被请求的功能代码。 处理结束之后，监控程序恢复系统调用之前的现场；把运行模式从特权模式恢复成为用户方式；最后将控制权转移到原来的用户程序。 SPOOLing技术（假脱技术） 基本思想： 用磁盘设备作为主机的直接输入/输出设备，主机直接从磁盘上选取作业运行，作业的执行结果也存在磁盘上；相应的，通道则负责将用户作业从卡片机上动态写入磁盘，而这一操作与主机并行。 ","date":"2017-11-18","objectID":"/os-introduction/:2:8","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"分时系统 基本工作方式 在分时系统中，一台计算机主机连接了若干个终端，每个终端可有一个用户使用。 设计思想 分时系统将CPU的时间划分成若干个小片段，称为时间片。操作系统以时间片为单位，轮流为每个终端用户服务。 特点 多路性： 只有多个用户在使用同一台计算机。 交互性： 指用户根据系统响应的结果提出下一个请求。 独占性： 指每个用户感觉不到计算机在为其他人服务。 及时性： 指系统能够对用户提出的请求及时给予响应。 分时操作系统追求的目标 ：及时响应用户输入的交互命令。 分时与批处理的处理原则 ：分时优先，批处理在后。 ","date":"2017-11-18","objectID":"/os-introduction/:2:9","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"实时操作系统 实时操作系统（RTOS）是指计算机能在规定的时间内及时响应外部事件的请求，同时完成对该事件的处理，并能够控制所有实时设备和实时任务协调一致の工作的操作系统。 硬实时系统 对关键外部事件的响应和处理时间有着极为严格的要求，系统必须满足这种严格的时间要求，否则会产生严重的不良后果。 软实时系统 对事件的响应和处理时间有一定的时间范围要求，不能满足相关的要求会影响系统的服务质量，但是通常不会引发灾难性后果。 实时时钟管理 主要设计目标：对实时任务能够进行实时处理。 依据时间要求 定时任务： 依据用户定时启动并按照严格的时间间隔重复运行。 延时任务： 非周期运行，允许被延后执行，但往往有一个严格的时间线界限。 依据功能划分 主动式任务： 依据时间间隔主动运行，多用于实时监控。 从动式任务： 运行以来于外部时间的发生，但外部事件出现时，这种实时任务应尽可能地进行处理，并且保证不丢失现象。 过载防护 实时任务的启动时间和数量具有很大的随机性，突发的大量实时任务极有可能超出系统的处理能力，从而发生过载。 高可靠性 ","date":"2017-11-18","objectID":"/os-introduction/:2:10","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"嵌入式操作系统EOS 嵌入式操作系统就是运行在嵌入式环境芯片中，对整个芯片以及它所操作的、控制的各种部件装置等资源进行统一协调、调度、指挥和控制的系统软件。 优点 具有高可靠性、实时性、占用资源少、智能化能源管理、易于连接、低成本等优点。 个人计算机操作系统PCOS 个人计算机操作系统是一种单用户多任务的操作系统。 网络操作系统NOS 网络操作系统：为计算机网络配置的操作系统。 分布式操作系统DOS 将大量计算机通过网络连接在一起，可以获得极高的运算能力及广泛的数据共享。 特征： 是一个统一的操作系统。 实现资源的深度共享。 透明性。 自治性。 集群 Cluster是分布式系统的一种，一个集群通常由一群处理器密集构成，集群操作系统专门服务于这样的集群。用低成本的微型计算机和以太网设备等产品，构造出性能相当于超级计算机运行性能的集群。 智能卡操作系统COS 四个基本功能：资源管理、通信管理、安全管理和应用管理。 ","date":"2017-11-18","objectID":"/os-introduction/:2:11","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["os"],"content":"操作系统结构 操作系统结构就是指操作系统各部分程序存在方式及相互关系。 模块结构： 以程序模块方式存在。 进程结构： 以进程的方式存在。 整体式结构 模块 将总功能分解成若干个子功能，实现每个子功能的程序。 优点：结构紧密，接口简单直接，系统效率较高。 模块组合法 （又称无需模块法，模块接口法），系统中的模块不是根据程序和数据本身的特性而是根据他们完成的功能来划分的，数据基本上作为全称量使用。 层次结构 层次结构就是把操作系统的所有功能模块，按照功能流程图的调用次序，分别将这些模块排列成若干层，各层之间的模块只能是单项依赖或则单先调用 。 全序的层次关系： 每一层中的同层模块之间不存在相互调用的关系。 优点： 整体问题局部化 各模块之间的组织架构和依赖关系清晰明了。 分层原则： 可适应性，方便于系统一直，可放在仅靠硬件的最底层。BIOS但硬件系统环境改变时只需要修改这一层模块就可以。 多种操作方式， 共同要使用的基本部分放在内层，而改变的部分放在外层。 微内核结构（C/S结构） 采用C/S结构的操作系统适宜于应用在网络环境下分布式处理的计算环境。 特点： 运行在核心态的内核：线程调度、虚拟内存、信息传递、设备驱动以及内核的原语操作集中中断处理等。 运行在用户态的并以C/S方式运行的进程层：除内核部分外，操作系统所有的其他部分被分成若干个相对独立的进程，每一个进程实现一组服务，称为服务进程。 这些服务进程可以提供各种系统功能、文件系统服务以及网络服务等。 好处： 可靠： 每一个分支是独立的，不会引起其他组成部分的损坏或崩溃。 灵活： 是自包含的，且接口规范，可维护性好。 分布式处理：具有分布式处理的能力。 缺点： 效率较低。 ","date":"2017-11-18","objectID":"/os-introduction/:2:12","tags":["os","system"],"title":"操作系统 概论","uri":"/os-introduction/"},{"categories":["tools"],"content":"安装 Sublime text3 软件 官方网址：https://www.sublimetext.com/3 选择Windows - also available as a portable version一项，点击下载安装。 ","date":"2017-11-12","objectID":"/sublime-text/:1:0","tags":["sublime","tools"],"title":"Sublime Text 崇高的文本编辑器","uri":"/sublime-text/"},{"categories":["tools"],"content":"安装 packagecontrol 插件 官方网址：https://packagecontrol.io/ 选择 Installation 项 选择 SUBLIME TEXT3 代码进行复制 打开 sublime text3 软件，选择 View-\u003eShow Console 选项（或者按 Ctrl+~组合键），调出命令行，将代码粘贴至命令行，回车，进行安装 packagecontrol 插件； 安装好之后在菜单栏Preferences栏目中会有packagecontrol选项，即安装成功。 ","date":"2017-11-12","objectID":"/sublime-text/:2:0","tags":["sublime","tools"],"title":"Sublime Text 崇高的文本编辑器","uri":"/sublime-text/"},{"categories":["tools"],"content":"安装汉化插件 ChineseLocalization 安装 sublime 汉化插件 ChineseLocalization 在弹出的框中，由于网速原因，请耐心等待…… 输入插件名称ChineseLocalization，回车[enter]进行安装 ","date":"2017-11-12","objectID":"/sublime-text/:3:0","tags":["sublime","tools"],"title":"Sublime Text 崇高的文本编辑器","uri":"/sublime-text/"},{"categories":["tools"],"content":"各类插件安装推荐 其他插件均和 ChineseLocalization 插件安装过程一样，在此不再重复操作，只推荐几款插件。 ","date":"2017-11-12","objectID":"/sublime-text/:4:0","tags":["sublime","tools"],"title":"Sublime Text 崇高的文本编辑器","uri":"/sublime-text/"},{"categories":["tools"],"content":"必备的插件安装 (初学者推荐安装) Emmet Emmet 的前身是大名鼎鼎的 Zen coding，如果你从事Web前端开发的话，对该插件一定不会陌生。它使用仿 CSS 选择器的语法来生成代码，大大提高了 HTML/CSS 代码编写的速度。 PySide PySide 是跨平台的应用程序框架 Qt 的 Python 绑定版本。 AutoFileName 一款在 Sublime Text 中可以自动补全文件路径及名称的插件。 DocBlockr DocBlockr 是一款 Sublime Text 2 \u0026 3 都可以使用的代码快注释插件。支持的语言有：JavaScript (including ES6), PHP, ActionScript, Haxe,CoffeeScript, TypeScript, Java, Groovy, Objective C, C, C++ and Rust. BracketHighlighter BracketHighlighter 是一款 Sublime 下匹配标签高亮的小插件，可以把匹配到的如 {}、()、”、””等对应的符号或者标签高亮显示。 Browser Refresh 通过一个快捷键可以实现保存文件，切换到浏览器并自动刷新浏览器来查看更改结果。 ConvertToUTF8 解决文档保存编码问题。 ColorPicker 一个多平台的颜色选择器插件。默认情况下，十六进制颜色代码使用大写字母插入。 ","date":"2017-11-12","objectID":"/sublime-text/:4:1","tags":["sublime","tools"],"title":"Sublime Text 崇高的文本编辑器","uri":"/sublime-text/"},{"categories":["tools"],"content":"进阶的程序猿推荐插件安装 a file icon 美化插件。可以更清楚了解每个文件的类型，一目了然。 git 版本控制仓库，推荐学习使用。 ","date":"2017-11-12","objectID":"/sublime-text/:4:2","tags":["sublime","tools"],"title":"Sublime Text 崇高的文本编辑器","uri":"/sublime-text/"}]